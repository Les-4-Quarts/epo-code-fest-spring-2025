{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83665d82",
   "metadata": {},
   "source": [
    "# Generate testset\n",
    "\n",
    "In this notebook, we generate a testset with a model v0.1.0. The goad is to be able to have a representative testset. So we want to classify a lot of Patents and shuffle them and take few sample of each class. After this we verify manualy each class to label them correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6518816",
   "metadata": {},
   "source": [
    "## Step 1. Generage initial predictions\n",
    "\n",
    "We classify all patents using the model from 02-classify_patent_v0.1.0.ipynb.\n",
    "For each patent description, we store: num_patent, num_desc, desc, sdg_pred, score.\n",
    "The results are saved in classified_patents_raw.jsonl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb241012",
   "metadata": {},
   "source": [
    "### üîπ Step 1.1. Load all Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number = get_all_patents_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare and report the result\n",
    "patents_metadata = get_all_patents()\n",
    "total_expected = patents_metadata.total_count\n",
    "\n",
    "print(f\"Expected total patents: {total_expected}\")\n",
    "print(f\"Total patent numbers collected: {len(all_patents_number)}\")\n",
    "print(f\"Retrieved unique patent numbers: {len(list(set(all_patents_number)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bfb9e",
   "metadata": {},
   "source": [
    "### üîπ Step 1.2. Analyse patents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e98f1",
   "metadata": {},
   "source": [
    "#### 1.2.1. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from api.config.ai_config import ai_huggingface_token\n",
    "from api.models.Patent import FullPatent\n",
    "from api.repositories.patent_repository import update_full_patent\n",
    "\n",
    "# Dict of SDG candidate labels\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}\n",
    "\n",
    "candidate_label_values = list(sdg_labels_dict.values())\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\", token=ai_huggingface_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdg_code_from_label(label: str, label_dict: dict) -> str:\n",
    "    \"\"\"Reverse lookup SDG code from full label text.\"\"\"\n",
    "    for code, text in label_dict.items():\n",
    "        if label == text:\n",
    "            return code\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "def classify_full_patent_description(patent: FullPatent,\n",
    "                                     classifier=classifier,\n",
    "                                     candidate_labels=candidate_label_values,\n",
    "                                     label_dict=sdg_labels_dict,\n",
    "                                     treshold: float = 0.18) -> FullPatent:\n",
    "    \"\"\"\n",
    "    Classify all description blocks in a FullPatent and enrich them with SDG labels.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent to analyze.\n",
    "        classifier: HuggingFace classifier.\n",
    "        candidate_labels (list): SDG label texts.\n",
    "        label_dict (dict): Map from SDG label text to SDG code.\n",
    "        treshold (float): Minimum score to accept prediction.\n",
    "\n",
    "    Returns:\n",
    "        FullPatent: Enriched object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Filter descriptions with enough length\n",
    "    valid_descriptions = [(desc, desc.description_text) \n",
    "                          for desc in patent.description \n",
    "                          if len(desc.description_text.split()) > 20]\n",
    "\n",
    "    # Step 2: Extract just the text for classification\n",
    "    texts_to_classify = [text for _, text in valid_descriptions]\n",
    "\n",
    "    # Step 3: Run classifier on batch\n",
    "    results = classifier(texts_to_classify, candidate_labels=candidate_labels)\n",
    "\n",
    "    # Step 4: Assign results back to descriptions\n",
    "    for (desc, _), result in zip(valid_descriptions, results):\n",
    "\n",
    "        try:\n",
    "            top_score = result[\"scores\"][0]\n",
    "            if top_score >= treshold:\n",
    "                label_text = result[\"labels\"][0]\n",
    "                desc.sdg = get_sdg_code_from_label(label_text, label_dict)\n",
    "            else:\n",
    "                desc.sdg = \"None\"\n",
    "                top_score = -1\n",
    "\n",
    "            # print(f\"[{desc.description_number}] Label: {desc.sdg} | Score: {top_score:.3f} | Text: {desc.description_text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error on description {desc.description_number}: {e}\")\n",
    "            desc.sdg = \"Error\"\n",
    "\n",
    "    # Step 5: Handle short descriptions (not classified)\n",
    "    for desc in patent.description:\n",
    "        if len(desc.description_text.split()) <= 20:\n",
    "            desc.sdg = \"None\"\n",
    "\n",
    "    patent.is_analyzed = True\n",
    "\n",
    "    # Update the Patent in Database\n",
    "    update_full_patent(patent.model_dump())\n",
    "\n",
    "    return patent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc948a",
   "metadata": {},
   "source": [
    "#### 1.2.2. Run analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cceb8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "\n",
    "def load_already_classified_patents(file_path: str) -> set:\n",
    "    \"\"\"Charge les brevets d√©j√† enregistr√©s dans le fichier JSONL.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "\n",
    "    classified = set()\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                classified.add(item[\"patent_number\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading line: {e}\")\n",
    "    return classified\n",
    "\n",
    "\n",
    "def save_classified_descriptions(data: List[Dict], file_path: str):\n",
    "    \"\"\"Ajoute les nouvelles descriptions √† la fin du fichier JSONL.\"\"\"\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def analyze_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "    random.shuffle(to_process)\n",
    "\n",
    "    for patent_number in to_process:\n",
    "        try:\n",
    "            print(f\"\\nProcessing patent {patent_number}...\")\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            enriched_patent = classify_full_patent_description(patent)\n",
    "\n",
    "            output_data = []\n",
    "            for desc in enriched_patent.description:\n",
    "                output_data.append({\n",
    "                    \"patent_number\": patent_number,\n",
    "                    \"description_number\": desc.description_number,\n",
    "                    \"description_text\": desc.description_text,\n",
    "                    \"sdg\": desc.sdg\n",
    "                })\n",
    "\n",
    "            save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36024da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation :\n",
    "analyze_patents_and_save_descriptions([\"EP4516252A2\", \"EP4518254A1\", \"EP3786627A1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse all patents\n",
    "analyze_patents_and_save_descriptions(all_patents_number, export_file=\"classified_patents_raw_v2.jsonl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9132a017",
   "metadata": {},
   "source": [
    "### üîπ Step 1.3. Generate testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a19e06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from typing import List\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0  # R√©sultats reproductibles\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang in {\"fr\", \"en\", \"de\"}:\n",
    "            return lang\n",
    "    except LangDetectException:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def generate_classified_patents_raw(\n",
    "    jsonl_file: str,\n",
    "    version: str = \"v0\",\n",
    "    max_per_sdg: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimis√© : D√©tection de langue par patent_number (unique), appliqu√©e √† tous ses √©l√©ments.\n",
    "    Affiche aussi les stats par SDG.\n",
    "    \"\"\"\n",
    "    # 1. Regrouper par patent_number\n",
    "    items_by_patent = defaultdict(list)\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                patent_number = item.get(\"patent_number\")\n",
    "                if patent_number:\n",
    "                    items_by_patent[patent_number].append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    # 2. D√©tecter la langue une seule fois par patent_number\n",
    "    grouped_by_lang = {\n",
    "        \"fr\": defaultdict(list),\n",
    "        \"en\": defaultdict(list),\n",
    "        \"de\": defaultdict(list)\n",
    "    }\n",
    "\n",
    "    for patent_number, items in items_by_patent.items():\n",
    "        # Prendre le premier √©l√©ment avec texte non vide\n",
    "        for item in items:\n",
    "            text = item.get(\"description_text\", \"\").strip()\n",
    "            if text:\n",
    "                lang = detect_language(text)\n",
    "                break\n",
    "        else:\n",
    "            lang = None\n",
    "\n",
    "        if lang in grouped_by_lang:\n",
    "            for item in items:\n",
    "                sdg = item.get(\"sdg\")\n",
    "                if sdg is not None:\n",
    "                    grouped_by_lang[lang][sdg].append(item)\n",
    "\n",
    "    # 3. G√©n√©rer les fichiers par langue\n",
    "    for lang, grouped in grouped_by_lang.items():\n",
    "        testset: List[dict] = []\n",
    "        per_class_count = {}\n",
    "        for sdg, items in grouped.items():\n",
    "            random.shuffle(items)\n",
    "            selected = items[:max_per_sdg]\n",
    "            testset.extend(selected)\n",
    "            per_class_count[sdg] = len(selected)\n",
    "\n",
    "        output_file = f\"testset_{version}_{lang}_raw.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "            json.dump(testset, out, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"\\n{output_file} g√©n√©r√© avec {len(testset)} √©l√©ments.\")\n",
    "        print(\"R√©partition par SDG :\")\n",
    "        for sdg in sorted(per_class_count):\n",
    "            print(f\"  SDG {sdg:>2}: {per_class_count[sdg]} √©l√©ments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"classified_patents_raw_test.jsonl\", version=\"test\", max_per_sdg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a03348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def trouver_doublons(fichier_json):\n",
    "    \"\"\"\n",
    "    Trouve les doublons dans un fichier JSON selon 'patent_number' et 'description_number'.\n",
    "\n",
    "    :param fichier_json: Chemin vers le fichier JSON\n",
    "    :return: Liste des doublons (chacun sous forme de dict)\n",
    "    \"\"\"\n",
    "    with open(fichier_json, 'r', encoding='utf-8') as f:\n",
    "        donnees = json.load(f)\n",
    "\n",
    "    vus = defaultdict(list)\n",
    "    doublons = []\n",
    "\n",
    "    for item in donnees:\n",
    "        cle = (item['patent_number'], item['description_number'])\n",
    "        vus[cle].append(item)\n",
    "\n",
    "    for items in vus.values():\n",
    "        if len(items) > 1:\n",
    "            doublons.extend(items)\n",
    "\n",
    "    return doublons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trouver_doublons(\"testset_test_en_raw.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752bd17",
   "metadata": {},
   "source": [
    "## Temporaire pour v√©rifier qualit√© de notre classification ant√©rieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90ebab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'classified_patents_raw.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_lines, duplicate_lines, duplicate_patents\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Exemple d'utilisation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m _, _, duplicate_patents = \u001b[43manalyze_jsonl_by_patent_and_description\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclassified_patents_raw.jsonl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(duplicate_patents))))\n\u001b[32m     34\u001b[39m duplicate_patents[\u001b[32m366\u001b[39m:\u001b[32m370\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36manalyze_jsonl_by_patent_and_description\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      6\u001b[39m duplicate_lines = \u001b[32m0\u001b[39m\n\u001b[32m      7\u001b[39m duplicate_patents = []\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'classified_patents_raw.jsonl'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def analyze_jsonl_by_patent_and_description(file_path):\n",
    "    seen_pairs = set()\n",
    "    total_lines = 0\n",
    "    duplicate_lines = 0\n",
    "    duplicate_patents = []\n",
    "\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                total_lines += 1\n",
    "                item = json.loads(line.strip())\n",
    "                pair = (item.get(\"patent_number\"), item.get(\"description_number\"))\n",
    "\n",
    "                if pair in seen_pairs:\n",
    "                    duplicate_lines += 1\n",
    "                    duplicate_patents.append(item.get(\"patent_number\"))\n",
    "                else:\n",
    "                    seen_pairs.add(pair)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "    print(f\"Duplicate (patent_number, description_number) pairs: {duplicate_lines}\")\n",
    "    print(f\"Unique (patent_number, description_number) pairs: {len(seen_pairs)}\")\n",
    "\n",
    "    return total_lines, duplicate_lines, duplicate_patents\n",
    "\n",
    "# Exemple d'utilisation\n",
    "_, _, duplicate_patents = analyze_jsonl_by_patent_and_description('classified_patents_raw.jsonl')\n",
    "print(len(list(set(duplicate_patents))))\n",
    "duplicate_patents[366:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(set(duplicate_patents))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850b6c4",
   "metadata": {},
   "source": [
    "## R√©cup√©rer donn√©es lab√©lis√©s depuis la DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2fe440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa5c68dd8a4a4eb84cf8d2e5b2c626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching patent numbers by batch:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number_if_analysed():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            if patent.is_analyzed:\n",
    "                all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number_if_analysed = get_all_patents_number_if_analysed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267f1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def db_get_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "\n",
    "\n",
    "    for patent_number in tqdm(to_process, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            # If analysed patent save it\n",
    "            if patent.is_analyzed:\n",
    "                output_data = []\n",
    "                for desc in patent.description:\n",
    "                    output_data.append({\n",
    "                        \"patent_number\": patent_number,\n",
    "                        \"description_number\": desc.description_number,\n",
    "                        \"description_text\": desc.description_text,\n",
    "                        \"sdg\": desc.sdg\n",
    "                    })\n",
    "\n",
    "                save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab86d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patents to process: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fbfcf0fec94600a90d55368e863034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patent recovered: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed and data saved.\n"
     ]
    }
   ],
   "source": [
    "db_get_patents_and_save_descriptions(all_patents_number_if_analysed, export_file=\"classified_patents_raw_v2.jsonl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "023d7e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 291654\n",
      "Duplicate (patent_number, description_number) pairs: 0\n",
      "Unique (patent_number, description_number) pairs: 291654\n"
     ]
    }
   ],
   "source": [
    "_, _, duplicate_patents = analyze_jsonl_by_patent_and_description('classified_patents_raw_v2.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7de9ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testset_v2_fr_raw.json g√©n√©r√© avec 98 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG1: 1 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 6 √©l√©ments\n",
      "  SDG SDG14: 10 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 3 √©l√©ments\n",
      "  SDG SDG17: 6 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v2_en_raw.json g√©n√©r√© avec 122 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG11: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 10 √©l√©ments\n",
      "  SDG SDG14: 8 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 7 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 10 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG8: 3 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v2_de_raw.json g√©n√©r√© avec 78 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 2 √©l√©ments\n",
      "  SDG SDG14: 9 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 1 √©l√©ments\n",
      "  SDG SDG2: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n"
     ]
    }
   ],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"classified_patents_raw_v2.jsonl\", version=\"v2\", max_per_sdg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e67a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons(\"testset_v2_en_raw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa0798b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons(\"testset_v2_fr_raw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "177351d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons(\"testset_v2_de_raw.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adca1f",
   "metadata": {},
   "source": [
    "### On explique que pour l'affichage on g√©n√®re les summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0cbe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.models.Patent import FullPatent\n",
    "from api.models.SDGSummary import SDGSummary\n",
    "\n",
    "def generate_summary(patent: FullPatent,\n",
    "                     ai_client,\n",
    "                     ai_model: str,\n",
    "                     sdg_labels_dict: dict) -> list[SDGSummary]:\n",
    "    \"\"\"\n",
    "    Generate SDG justification summaries for a FullPatent.\n",
    "\n",
    "    This function groups description blocks by their assigned SDG labels \n",
    "    (excluding \"None\" or \"Error\"), then uses an AI model to generate a \n",
    "    summary explaining how the content supports the respective SDG.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent object containing the description blocks.\n",
    "        ai_client: AI client used to generate summaries.\n",
    "        ai_model (str): The identifier of the AI model to be used.\n",
    "        sdg_labels_dict (dict): Mapping from SDG codes to their textual descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list[SDGSummary]: A list of SDGSummary objects created for the patent.\n",
    "    \"\"\"\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    # Group descriptions by SDG label, excluding \"None\" and \"Error\"\n",
    "    sdg_to_descriptions = {}\n",
    "    for desc in patent.description:\n",
    "        if desc.sdg not in [\"None\", \"Error\"]:\n",
    "            sdg_to_descriptions.setdefault(desc.sdg, []).append(desc)\n",
    "\n",
    "    for sdg_code, descriptions in tqdm(sdg_to_descriptions.items(), desc=f\"Generating summaries for patent {patent.number}\"):\n",
    "        try:\n",
    "            sdg_description = sdg_labels_dict[sdg_code]\n",
    "            combined_text = \"\\n\".join(desc.description_text for desc in descriptions)\n",
    "\n",
    "            system_prompt = f\"\"\"\n",
    "            You are an AI specialized in sustainable development and patents. Read the following patent excerpt and explain how it contributes to this Sustainable Development Goal (SDG): {sdg_code} - {sdg_description}.\n",
    "\n",
    "            Focus on:\n",
    "            - The main innovation or idea in the patent.\n",
    "            - How it supports the targets of the SDG.\n",
    "            - Any positive impact (social, environmental, or economic) it may have.\n",
    "\n",
    "            Patent text:\n",
    "            {combined_text}\n",
    "\n",
    "            Write a short, clear summary showing the link between the patent and the SDG.\n",
    "            \"\"\"\n",
    "\n",
    "            user_prompt = f\"\"\"\n",
    "            Summarize how this patent helps achieve the SDG: {sdg_code} - {sdg_description}.\"\"\"\n",
    "\n",
    "            response = ai_client.chat(\n",
    "                model=ai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}],\n",
    "                options = {\"num_predict\":512}\n",
    "            )\n",
    "\n",
    "            summary_text = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            summary = SDGSummary(\n",
    "                patent_number=str(patent.number),\n",
    "                sdg=str(sdg_code),\n",
    "                sdg_description=summary_text\n",
    "            )\n",
    "\n",
    "            summaries.append(summary)\n",
    "\n",
    "            # print(f\"[{patent.number}] SDG: {sdg_code} | Summary:\\n{summary_text}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary for SDG {sdg_code} in patent {patent.number}: {e}\")\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46402363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.repositories.sdg_summary_repository import get_sdg_summary_by_patent_number\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "from api.repositories.sdg_summary_repository import create_sdg_summary\n",
    "from api.config.ai_config import ai_model, ai_client\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_summaries_for_patent_in_db_analysed(patent_numbers: List[str]):\n",
    "\n",
    "    for patent_number in tqdm(patent_numbers, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            # We check if a summary already exists\n",
    "            summaries = get_sdg_summary_by_patent_number(patent_number)\n",
    "\n",
    "            if not summaries:\n",
    "                patent = get_full_patent_by_number(patent_number)\n",
    "                summaries = generate_summary(patent, ai_client, ai_model, sdg_labels_dict)\n",
    "                \n",
    "                # Save in bdd\n",
    "                for summary in summaries:\n",
    "                    create_sdg_summary(summary.model_dump())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and summaries generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3f4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479df5905b214a53b5348796aa5583f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patent recovered:   0%|          | 0/2477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf207c60506b4d4e8526d54440c0751b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating summaries for patent EP4434779A1:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 21:27:19,244 - httpx - INFO - _send_single_request - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "generate_summaries_for_patent_in_db_analysed(all_patents_number_if_analysed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
