{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231ab768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in ./.venv/lib/python3.12/site-packages (2025.5.7)\n",
      "Requirement already satisfied: vllm in ./.venv/lib/python3.12/site-packages (0.8.5.post1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.5.8 in ./.venv/lib/python3.12/site-packages (from unsloth) (2025.5.8)\n",
      "Requirement already satisfied: torch>=2.4.0 in ./.venv/lib/python3.12/site-packages (from unsloth) (2.6.0)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in ./.venv/lib/python3.12/site-packages (from unsloth) (0.0.29.post2)\n",
      "Requirement already satisfied: bitsandbytes in ./.venv/lib/python3.12/site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: triton>=3.0.0 in ./.venv/lib/python3.12/site-packages (from unsloth) (3.2.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: tyro in ./.venv/lib/python3.12/site-packages (from unsloth) (0.9.21)\n",
      "Requirement already satisfied: transformers!=4.47.0,==4.51.3 in ./.venv/lib/python3.12/site-packages (from unsloth) (4.51.3)\n",
      "Requirement already satisfied: datasets>=3.4.1 in ./.venv/lib/python3.12/site-packages (from unsloth) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in ./.venv/lib/python3.12/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in ./.venv/lib/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from unsloth) (2.2.6)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in ./.venv/lib/python3.12/site-packages (from unsloth) (1.7.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in ./.venv/lib/python3.12/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in ./.venv/lib/python3.12/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in ./.venv/lib/python3.12/site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.12/site-packages (from unsloth) (0.32.0)\n",
      "Requirement already satisfied: hf_transfer in ./.venv/lib/python3.12/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in ./.venv/lib/python3.12/site-packages (from unsloth) (0.33.1)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.12/site-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub->unsloth) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.12/site-packages (from huggingface_hub->unsloth) (1.1.2)\n",
      "Requirement already satisfied: rich in ./.venv/lib/python3.12/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Requirement already satisfied: cachetools in ./.venv/lib/python3.12/site-packages (from vllm) (6.0.0)\n",
      "Requirement already satisfied: blake3 in ./.venv/lib/python3.12/site-packages (from vllm) (1.0.5)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.12/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in ./.venv/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from vllm) (3.12.0)\n",
      "Requirement already satisfied: openai>=1.52.0 in ./.venv/lib/python3.12/site-packages (from vllm) (1.82.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in ./.venv/lib/python3.12/site-packages (from vllm) (2.11.5)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in ./.venv/lib/python3.12/site-packages (from vllm) (0.22.0)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.12/site-packages (from vllm) (11.2.1)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in ./.venv/lib/python3.12/site-packages (from vllm) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in ./.venv/lib/python3.12/site-packages (from vllm) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in ./.venv/lib/python3.12/site-packages (from vllm) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in ./.venv/lib/python3.12/site-packages (from vllm) (0.7.24)\n",
      "Requirement already satisfied: outlines==0.1.11 in ./.venv/lib/python3.12/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in ./.venv/lib/python3.12/site-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.18 in ./.venv/lib/python3.12/site-packages (from vllm) (0.1.18)\n",
      "Requirement already satisfied: partial-json-parser in ./.venv/lib/python3.12/site-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in ./.venv/lib/python3.12/site-packages (from vllm) (26.4.0)\n",
      "Requirement already satisfied: msgspec in ./.venv/lib/python3.12/site-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf>=0.13.0 in ./.venv/lib/python3.12/site-packages (from vllm) (0.16.3)\n",
      "Requirement already satisfied: importlib_metadata in ./.venv/lib/python3.12/site-packages (from vllm) (8.0.0)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in ./.venv/lib/python3.12/site-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.6)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in ./.venv/lib/python3.12/site-packages (from vllm) (4.11.0.86)\n",
      "Requirement already satisfied: six>=1.16.0 in ./.venv/lib/python3.12/site-packages (from vllm) (1.17.0)\n",
      "Requirement already satisfied: setuptools>=74.1.1 in ./.venv/lib/python3.12/site-packages (from vllm) (80.8.0)\n",
      "Requirement already satisfied: einops in ./.venv/lib/python3.12/site-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.3 in ./.venv/lib/python3.12/site-packages (from vllm) (0.9.3)\n",
      "Requirement already satisfied: depyf==0.18.0 in ./.venv/lib/python3.12/site-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.12/site-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in ./.venv/lib/python3.12/site-packages (from vllm) (1.0.5)\n",
      "Requirement already satisfied: python-json-logger in ./.venv/lib/python3.12/site-packages (from vllm) (3.3.0)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from vllm) (1.15.3)\n",
      "Requirement already satisfied: ninja in ./.venv/lib/python3.12/site-packages (from vllm) (1.11.1.4)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.27.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-api<1.27.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp<1.27.0,>=1.26.0 in ./.venv/lib/python3.12/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 in ./.venv/lib/python3.12/site-packages (from vllm) (0.4.9)\n",
      "Requirement already satisfied: numba==0.61.2 in ./.venv/lib/python3.12/site-packages (from vllm) (0.61.2)\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in ./.venv/lib/python3.12/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.46.0)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in ./.venv/lib/python3.12/site-packages (from vllm) (2.6.0)\n",
      "Requirement already satisfied: astor in ./.venv/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.12/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.12/site-packages (from numba==0.61.2->vllm) (0.44.0)\n",
      "Requirement already satisfied: interegular in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (20250523)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in ./.venv/lib/python3.12/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.12/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.26.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.26.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.26.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm) (0.47b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2025.4.26)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets>=3.4.1->unsloth) (20.0.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets>=3.4.1->unsloth) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->vllm) (1.20.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic>=2.9->vllm) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.5 in ./.venv/lib/python3.12/site-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in ./.venv/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in ./.venv/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in ./.venv/lib/python3.12/site-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./.venv/lib/python3.12/site-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in ./.venv/lib/python3.12/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.4)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in ./.venv/lib/python3.12/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.6)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.25.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai>=1.52.0->vllm) (0.10.0)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: cupy-cuda12x in ./.venv/lib/python3.12/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: cut_cross_entropy in ./.venv/lib/python3.12/site-packages (from unsloth_zoo>=2025.5.8->unsloth) (25.1.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in ./.venv/lib/python3.12/site-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in ./.venv/lib/python3.12/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./.venv/lib/python3.12/site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in ./.venv/lib/python3.12/site-packages (from tyro->unsloth) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f23c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magb/project/epo-code-fest-spring-2025/backend/notebooks/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-25 19:09:22 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-25 19:09:22 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 19:09:23,688\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "from transformers import AutoModelForCausalLM\n",
    "from datasets import Dataset \n",
    "\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9070f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1326 items from dataset_labeled.jsonl\n",
      "Loaded 3000 items from dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the labeled dataset (solutions)\n",
    "labeled_items = []\n",
    "with open(\"../src/ai/testsets/dataset_labeled.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip(): # Make sure the line is not empty\n",
    "            labeled_items.append(json.loads(line.strip()))\n",
    "\n",
    "# Load the descriptions dataset\n",
    "description_items = []\n",
    "with open(\"../src/ai/testsets/dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.strip(): # Make sure the line is not empty\n",
    "            description_items.append(json.loads(line.strip()))\n",
    "\n",
    "# Load the prompt template\n",
    "with open(\"sdg_label_prompt.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_template = f.read()\n",
    "\n",
    "print(f\"Loaded {len(labeled_items)} items from dataset_labeled.jsonl\")\n",
    "print(f\"Loaded {len(description_items)} items from dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015eb2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The number of items in labeled_items and description_items is different!\n",
      "Will process up to the length of the shorter list.\n",
      "Processed 1326 items for the dataset.\n",
      "{'solution': '3', 'prompt': \"A conversation between User and Assistant. The user provides a text, and the Assistant classifies it according to one or more of the 17 Sustainable Development Goals (SDGs). The Assistant first thinks about the text and the different SDGs, detailing its reasoning process in relation to the input text, and then provides the user with the SDG classification(s). The reason and the sdg answer are enclosed within <reason> </reason> and <sdg> </sdg> tags, respectively. The Assistant must identify the most relevant SDG(s) for the given text. If multiple SDGs are relevant, they can all be listed. The reasoning should clearly justify the choice(s).\\\\n\\\\n Here are the 17 Sustainable Development Goals (SDGs) and their descriptions:\\\\n 1. **SDG 1: No Poverty:** End poverty in all its forms everywhere.\\\\n 2. **SDG 2: Zero Hunger:** End hunger, achieve food security and improved nutrition and promote sustainable agriculture.\\\\n 3. **SDG 3: Good Health and Well-being:** Ensure healthy lives and promote well-being for all at all ages.\\\\n 4. **SDG 4: Quality Education:** Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all.\\\\n 5. **SDG 5: Gender Equality:** Achieve gender equality and empower all women and girls.\\\\n 6. **SDG 6: Clean Water and Sanitation:** Ensure availability and sustainable management of water and sanitation for all.\\\\n 7. **SDG 7: Affordable and Clean Energy:** Ensure access to affordable, reliable, sustainable and modern energy for all.\\\\n 8. **SDG 8: Decent Work and Economic Growth:** Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all.\\\\n 9. **SDG 9: Industry, Innovation and Infrastructure:** Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation.\\\\n 10. **SDG 10: Reduced Inequalities:** Reduce inequality within and among countries.\\\\n 11. **SDG 11: Sustainable Cities and Communities:** Make cities and human settlements inclusive, safe, resilient and sustainable.\\\\n 12. **SDG 12: Responsible Consumption and Production:** Ensure sustainable consumption and production patterns.\\\\n 13. **SDG 13: Climate Action:** Take urgent action to combat climate change and its impacts.\\\\n 14. **SDG 14: Life Below Water:** Conserve and sustainably use the oceans, seas and marine resources for sustainable development.\\\\n 15. **SDG 15: Life on Land:** Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss.\\\\n 16. **SDG 16: Peace, Justice and Strong Institutions:** Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels.\\\\n 17. **SDG 17: Partnerships for the Goals:** Strengthen the means of implementation and revitalize the global partnership for sustainable development. 18. **nothing:** the text is not related to SDG The text to be classified is: [A replaceable cartridge assembly (12) for a surgical stapling apparatus, the replaceable cartridge assembly comprising: a cartridge body (124) configured to support a plurality of surgical staples; and a connector assembly (160) secured to the cartridge body, the connector assembly including: a connector housing (162) having a base portion (164) and an extension portion (166) defining first and second recesses (163, 165; 163', 165'), first and second contact members (182, 184; 192, 194) disposed within the respective first and second recesses, and a seal member (168) supported on the housing and defining first and second apertures (167, 169) providing access to the first and second recesses. 1: The present disclosure relates to surgical stapling instruments including a replaceable cartridge assembly having an identification chip. More particularly, the present disclosure relates to electrical connectors for connecting the identification chip of a cartridge assembly of a surgical stapling instrument with a handle assembly of the stapling instrument. 2: Surgical stapling instruments for applying rows of surgical staples to tissue are well known in the art and typically include a powered handle assembly, a body portion extending distally from the handle assembly, and a stapling end effector that is supported on a distal end of the body portion and is articulable relative to the body portion. The stapling end effector includes first and second jaws which are movable in relation to each other between spaced and approximated positions. The first jaw supports an anvil assembly and the second jaw supports a cartridge assembly. The cartridge assembly may be replaceable to permit reuse of the end effector during a surgical procedure. The replaceable cartridge assembly may be provided in a variety of configurations for use on tissue having different properties, e.g., thickness, density. For example, the different cartridge assemblies may have different size staples and/or different configurations of staples. 3: Many cartridge assemblies include an identification chip that is electrically coupled to the handle assembly by a conductor extending through the body portion of the surgical stapling instrument to ensure the handle assembly is programmed to operate with the attached cartridge assembly. During attachment of the cartridge assembly to the surgical stapling instrument improper loading of the cartridge assembly may result in damage to the electrical connection between the cartridge assembly and the surgical stapling instrument. Similarly, exposure of the electrical connection to fluids during a surgical procedure may damage and significantly affect operation of the surgical stapling instrument. To prevent damage to the electrical connections during loading of the cartridge assembly and during use of the surgical stapling instrument, it would be beneficial to provide a cartridge assembly with improved electrical connections. 4: Accordingly, a surgical stapling instrument including a connector mechanism is provided. The surgical stapling instrument includes a proximal body portion configured for operable engagement with a handle assembly and a tool assembly extending from the proximal body portion. The tool assembly includes an anvil assembly, a jaw member pivotally secured relative to the anvil assembly, and a first connector assembly disposed within the jaw member. The first connector assembly includes a first connector housing and first and second connector members extending from the first connector housing. The surgical stapling instrument further includes a cartridge assembly selective receivable within the jaw member of the tool assembly. The cartridge assembly includes a second connector assembly configured for electrical connection with the first connector assembly when the cartridge assembly is received within the jaw member. The second connector assembly includes a second connector housing and first and second contact members disposed within the second connector housing. The first and second connector members of the first connector assembly are configured to engage the respective first and second contact members of the second connector housing when the cartridge assembly is received within the jaw member of the tool assembly. 5: In embodiments, the cartridge assembly includes a cartridge body and a support plate. The surgical stapling instrument may further include a handle assembly operably secured to the proximal body portion. The first and second connector assemblies may form a connector mechanism for electrically connecting the cartridge assembly with the handle assembly. The first and second connector members may each include a beveled leading edge. 6: In some embodiments, the first and second contact members each includes a coil spring. Alternatively, the first and second contact members may each include a leaf spring. Each of the leaf springs may include an inclined engagement surface. Each of the leaf springs may be configured to be deflected inward upon engagement with the respective first or\"}\n"
     ]
    }
   ],
   "source": [
    "prepared_data = []\n",
    "\n",
    "# Assuming labeled_items and description_items correspond line by line\n",
    "# and are of the same length.\n",
    "if len(labeled_items) != len(description_items):\n",
    "    print(\"Warning: The number of items in labeled_items and description_items is different!\")\n",
    "    print(\"Will process up to the length of the shorter list.\")\n",
    "\n",
    "for i in range(min(len(labeled_items), len(description_items))):\n",
    "    label_item = labeled_items[i]        # e.g., {\"patent_text_key\": \"This is the solution.\", \"reason\": \"...\"}\n",
    "    desc_item = description_items[i]     # e.g., {\"patent_text_key\": \"Full description for prompt.\", \"other_field\": \"...\"}\n",
    "\n",
    "    current_solution = None\n",
    "    description_for_prompt = None\n",
    "    \n",
    "    # Find the solution and the key that provided it\n",
    "    key_for_solution_and_description = None\n",
    "    for key, value in label_item.items():\n",
    "        if key != \"reason\":\n",
    "            current_solution = value\n",
    "            key_for_solution_and_description = key\n",
    "            break # Found the first non-reason item\n",
    "\n",
    "    if current_solution is not None and key_for_solution_and_description is not None:\n",
    "        # Now use this key_for_solution_and_description to get the description from desc_item\n",
    "        description_for_prompt = desc_item.get(key_for_solution_and_description)\n",
    "\n",
    "        if description_for_prompt is not None:\n",
    "            final_prompt = \" \".join(prompt_template.replace(\"{description}\", description_for_prompt).split()[:1200])\n",
    "            prepared_data.append({\n",
    "                'solution': current_solution,\n",
    "                'prompt': final_prompt\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: For item index {i}, solution found with key '{key_for_solution_and_description}', but this key was not found in the corresponding description item: {desc_item}\")\n",
    "    else:\n",
    "        print(f\"Warning: For item index {i}, no suitable solution key (non-'reason') found in label_item: {label_item}\")\n",
    "\n",
    "print(f\"Processed {len(prepared_data)} items for the dataset.\")\n",
    "print(prepared_data[0])\n",
    "train_dataset = Dataset.from_list(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ab9387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3070. Num GPUs = 1. Max memory: 8.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/Qwen3-0.6B with actual GPU utilization = 60.4%\n",
      "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 8.0 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2500. Num Sequences = 160.\n",
      "Unsloth: vLLM's KV Cache can use up to 3.85 GB. Also swap space = 0 GB.\n",
      "INFO 05-25 19:09:35 [config.py:717] This model supports multiple tasks: {'embed', 'score', 'generate', 'classify', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 05-25 19:09:35 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=2500.\n",
      "INFO 05-25 19:09:35 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='unsloth/Qwen3-0.6B', speculative_config=None, tokenizer='unsloth/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2500, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/Qwen3-0.6B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"backend\":\"inductor\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"debug\":false,\"dce\":true,\"coordinate_descent_tuning\":true,\"trace.enabled\":false,\"trace.graph_diagram\":false,\"triton.cudagraphs\":true,\"compile_threads\":48,\"max_autotune\":false,\"disable_progress\":false,\"verbose_progress\":true,\"enable_auto_functionalized_v2\":false},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-25 19:09:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8edee7e300>\n",
      "INFO 05-25 19:09:36 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "WARNING 05-25 19:09:36 [interface.py:314] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.\n",
      "INFO 05-25 19:09:36 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-25 19:09:36 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-25 19:09:36 [gpu_model_runner.py:1329] Starting to load model unsloth/Qwen3-0.6B...\n",
      "INFO 05-25 19:09:36 [weight_utils.py:265] Using model weights format ['*.safetensors']\n",
      "INFO 05-25 19:09:37 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.04it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-25 19:09:37 [loader.py:458] Loading weights took 0.37 seconds\n",
      "INFO 05-25 19:09:37 [punica_selector.py:18] Using PunicaWrapperGPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-25 19:09:38 [gpu_model_runner.py:1347] Model loading took 1.1649 GiB and 1.293368 seconds\n",
      "INFO 05-25 19:09:50 [backends.py:420] Using cache directory: /home/magb/.cache/vllm/torch_compile_cache/5b62dcf92c/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-25 19:09:50 [backends.py:430] Dynamo bytecode transform time: 12.28 s\n",
      "INFO 05-25 19:09:59 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 6.253 s\n",
      "INFO 05-25 19:10:05 [monitor.py:33] torch.compile takes 12.28 s in total\n",
      "INFO 05-25 19:10:06 [kv_cache_utils.py:634] GPU KV cache size: 15,312 tokens\n",
      "INFO 05-25 19:10:06 [kv_cache_utils.py:637] Maximum concurrency for 2,500 tokens per request: 6.12x\n",
      "INFO 05-25 19:10:57 [gpu_model_runner.py:1686] Graph capturing finished in 50 secs, took 0.63 GiB\n",
      "INFO 05-25 19:10:57 [core.py:159] init engine (profile, create kv cache, warmup model) took 79.39 seconds\n",
      "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n",
      "Unsloth: Just some info: will skip parsing ['post_feedforward_layernorm', 'pre_feedforward_layernorm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.5.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2500 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-0.6B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = False, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.7, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank*2, # *2 speeds up training\n",
    "    use_gradient_checkpointing = \"unsloth\", # Reduces memory usage\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50af5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<sdg>.*?</sdg>\\s*<reason>.*?</reason>$\"\n",
    "    print(completions)\n",
    "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
    "    matches = [re.match(pattern, content) for content in completion_contents]\n",
    "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
    "    return rewards_list\n",
    "\n",
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = r\"^<sdg>.*?</sdg>\\s*<reason>.*?</reason>$\"\n",
    "    \n",
    "    # 'completions' is already the list of strings you want to check.\n",
    "    # So, 'completion_contents' can just be 'completions'.\n",
    "    # Each 'content' in the next line will be one of the generated strings.\n",
    "    print(f\"Received completions: {completions}\") # This print is helpful for debugging\n",
    "\n",
    "    # Directly use each completion string for matching\n",
    "    matches = [re.match(pattern, single_completion_string) for single_completion_string in completions]\n",
    "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
    "    \n",
    "    print(f\"Generated rewards: {rewards_list}\") # Optional: to see the rewards\n",
    "    return rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bab275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdg_reason(text: str) -> Tuple[str, str]:\n",
    "    \"\"\"Extracts SDG (Sustainable Development Goal) and reason from a text.\n",
    "\n",
    "    The input text is expected to contain <sdg> and <reason> XML-like tags\n",
    "    enclosing the relevant information.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string, potentially containing SDG and reason\n",
    "            information enclosed in <sdg>...</sdg> and <reason>...</reason>\n",
    "            tags.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: A tuple containing two strings:\n",
    "            - The content of the <sdg> tag, stripped of leading/trailing\n",
    "              whitespace.\n",
    "            - The content of the <reason> tag, stripped of leading/trailing\n",
    "              whitespace.\n",
    "            Returns empty strings for either if the corresponding tag is not found.\n",
    "    \"\"\"\n",
    "    reason_match = re.search(r'<reason>(.*?)</reason>', text, re.DOTALL)\n",
    "    sdg_match = re.search(r'<sdg>(.*?)</sdg>', text, re.DOTALL)\n",
    "\n",
    "    reason_content_regex = \"\"\n",
    "    sdg_content_regex = \"\"\n",
    "\n",
    "    if reason_match:\n",
    "        reason_content_regex = reason_match.group(1).strip()\n",
    "\n",
    "    if sdg_match:\n",
    "        sdg_content_regex = sdg_match.group(1).strip()\n",
    "    return sdg_content_regex, reason_content_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9307f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sdgs(text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extracts and standardizes SDG references from a given text.\n",
    "\n",
    "        This method identifies SDG mentions in various formats, including:\n",
    "        - \"SDG\" followed by a number (e.g., \"SDG1\", \"SDG 2\").\n",
    "        - Numbers with sub-targets (e.g., \"16.1\", \"3.4\"), where the main number\n",
    "          is extracted.\n",
    "        - Standalone numbers (1-17) that appear at the beginning of the text\n",
    "          or are preceded by common delimiters (commas, semicolons, colons, whitespace)\n",
    "          and followed by delimiters or the end of the string.\n",
    "        The matching is case-insensitive.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text to scan for SDG references.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of unique SDGs found, formatted as \"SDG<number>\"\n",
    "                (e.g., [\"SDG1\", \"SDG2\"]), sorted numerically. Returns [\"None\"]\n",
    "                if no valid SDGs (1-17) are found or if the input text is empty\n",
    "                or not a string.\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            # Modified to return [\"None\"] as per original logic for empty/invalid text\n",
    "            return [\"None\"]\n",
    "\n",
    "        sdg_numbers = set()  # Use set to avoid duplicates\n",
    "\n",
    "        # Pattern 1: SDG followed by number with optional sub-target\n",
    "        # Captures: SDG1, sdg 2, SDG13.4, etc.\n",
    "        sdg_pattern = r'(?i)\\bsdg\\s*(\\d{1,2})(?:\\.\\d+)?\\b'\n",
    "        sdg_matches = re.findall(sdg_pattern, text)\n",
    "        for match in sdg_matches:\n",
    "            number = int(match)\n",
    "            if 1 <= number <= 17:\n",
    "                sdg_numbers.add(number)\n",
    "\n",
    "        # Pattern 2: Number with sub-target (e.g., \"16.1\", \"3.4\")\n",
    "        # Look for patterns like X.Y where X is 1-17\n",
    "        number_with_sub_pattern = r'\\b(\\d{1,2})\\.\\d+\\b'\n",
    "        sub_matches = re.findall(number_with_sub_pattern, text)\n",
    "        for match in sub_matches:\n",
    "            number = int(match)\n",
    "            if 1 <= number <= 17:\n",
    "                sdg_numbers.add(number)\n",
    "\n",
    "        # Pattern 3: Standalone numbers at beginning or after delimiters\n",
    "        standalone_pattern = r'(?:^|[,;:]\\s*|(?<=\\s))(\\d{1,2})(?=\\s*[,;]|\\s*$|\\s+)'\n",
    "        standalone_matches = re.findall(standalone_pattern, text.strip())\n",
    "        for match in standalone_matches:\n",
    "            number = int(match)\n",
    "            if 1 <= number <= 17:\n",
    "                sdg_numbers.add(number)\n",
    "\n",
    "        # Convert to sorted list of formatted strings\n",
    "        result = [f\"SDG{num}\" for num in sorted(sdg_numbers)]\n",
    "\n",
    "        return [\"None\"] if not result else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97e9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(list1: List[str], list2: List[str]) -> float:\n",
    "  \"\"\"Calculates a similarity score between two lists based on common elements.\n",
    "\n",
    "  The score is defined as the ratio of the number of common unique elements\n",
    "  to the total number of unique elements across both lists (Jaccard index\n",
    "  for sets derived from the lists).\n",
    "\n",
    "  Args:\n",
    "    list1 (List[Any]): The first list of items.\n",
    "    list2 (List[Any]): The second list of items.\n",
    "\n",
    "  Returns:\n",
    "    float: The similarity score, ranging from 0.0 (no common elements)\n",
    "           to 1.0 (all unique elements are common, or both lists are\n",
    "           effectively the same in terms of unique content if order and\n",
    "           duplicates are ignored). Returns 0.0 if both lists are empty\n",
    "           or if the union of elements is empty to avoid division by zero,\n",
    "           though the formula naturally handles this if at least one list\n",
    "           is non-empty.\n",
    "  \"\"\"\n",
    "  set1 = set(list1)\n",
    "  set2 = set(list2)\n",
    "\n",
    "  # Number of unique combined elements\n",
    "  num_union = len(set1 | set2)  # Union of sets\n",
    "\n",
    "  # Number of common elements between list2 and list1\n",
    "  num_intersection = len(set1 & set2)  # Intersection of sets\n",
    "\n",
    "  if num_union == 0:\n",
    "    return 0.0  # Avoid division by zero if both lists result in empty sets\n",
    "  return num_intersection / num_union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
    "    sdg_tag_solutions = kwargs[\"solution\"]\n",
    "    print(completions)\n",
    "    #completion_contents = [completion[0][\"content\"] for single_completion_string in completions]\n",
    "    rewards = []\n",
    "    for content, sdg_tag_solution in zip(completions, sdg_tag_solutions):\n",
    "        sdg_tag_content, _ = get_sdg_reason(content)\n",
    "\n",
    "        sdg_list = extract_sdgs(sdg_tag_content)\n",
    "        sdg_list_solution = extract_sdgs(sdg_tag_solution)\n",
    "        if len(sdg_list) != 0:\n",
    "            try:\n",
    "                rewards.append(score(sdg_list, sdg_list_solution))\n",
    "            except Exception:\n",
    "                rewards.append(0.0)\n",
    "        else:\n",
    "            rewards.append(0.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e1f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "max_prompt_length = 1500\n",
    "max_completion_length = max_seq_length - max_prompt_length\n",
    "\n",
    "from vllm import SamplingParams\n",
    "vllm_sampling_params = SamplingParams(\n",
    "    min_p = 0.1,\n",
    "    top_p = 1.0,\n",
    "    top_k = -1,\n",
    "    seed = 3407,\n",
    "    stop = [tokenizer.eos_token],\n",
    "    include_stop_str_in_output = True,\n",
    ")\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    vllm_sampling_params = vllm_sampling_params,\n",
    "    temperature = 1.0,\n",
    "    learning_rate = 5e-6,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"linear\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_completion_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 100,\n",
    "    save_steps = 10,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    "\n",
    "    # For optional training + evaluation\n",
    "    # fp16_full_eval = True,\n",
    "    # per_device_eval_batch_size = 4,\n",
    "    # eval_accumulation_steps = 1,\n",
    "    # eval_strategy = \"steps\",\n",
    "    # eval_steps = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe526af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,326 | Num Epochs = 1 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 20,185,088/616,235,008 (3.28% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received completions: [' truck-mounted radar subsystem is configured to emit electromagnetic waves propagating in a space under the trailer. The truck-mounted radar associated with the work described in this patent is designed for detecting objects in the space under the trailer and detecting object positions by sending a signal. 6: The configuration of the truck-mounted radar subsystem consistent with the example embodiment mentioned in the previous paragraph; the truck-mounted sensor is more accurate in detecting the objects in the area where they are observed and with the characteristics of conductivity, and adds the ability to sense objects with higher frequencies and a lower range of dust explosion and noise. However, the implementation cost for such a system is relatively high. 7: Presenters and authors contribute that the improvement in the system and method of truck-mounted sensors in this patent is significant and appropriate for use in the field of automotive engineering. 8: This patent document is exemplary in illustrating a method to detect and monitor various automotive systems, including and not limited to vehicles, asphalt, roadways, glass, and steel. 9: Regarding the problem of tractors and tractors causing an overlap in areas where they are used, such as in the traffic, and the effect of these overlapping areas on other vehicles or traffic constraints, the technical field is with the topic of this patent. 10: The issue described in this patent is related to wheelchair access, transportation, and mobility; it is not related to sustainable development goals. 11: The system and method of this patent described them; the example embodiment becomes a tractor trailer system and includes all the features described before. 12: This patent document does not distinguish between an object and a machine, nor between an object and a vehicle, and so does not provide any indication of discrimination. 13: The problem resides in the area where the electromagnetic waves leak outside. The original patent ignored this problem and cannot provide proper environmental settings for the sensor. 14: According to the patent, it describes a half-ellipse as a bluff shape for a part of the truck. The shape of the truck is the same as the shape of the half-ellipse. 15: The patent also describes a typical model, a guided guidance mode of the truck. 16: This patent does not talks about transfer or transfer notes. The text does not talk about transfer of documents or information, it discusses systems, methods of data acquisition, and the relationship between different parts of the truck-trailer system. Therefore, the text is not related to any of the SDGs specified in the list.\\nAnswer:\\n<reason> Since the text describes a system and method of truck-mounted sensors, it relates to SDG 13 (Climate Action) and SDG 12 (Responsible Consumption and Production). However, the text also mentions the problem with electromagnetic waves leaking outside the truck and the need for proper environmental settings, which relates to SDG 13. The invention involves detecting and monitoring different automotive systems, which aligns with SDG 13. The details about the sensor configurations and implementation may also relate to SDG 7 (Affordable and Clean Energy) if the sensors are used to detect and monitor energy-related objects. However, based on the provided SDGs and the specific information given, the most relevant SDGs are SDG 12 and SDG 13.</reason>\\n<sdg>12, 13</sdg>\\n</s>Source: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of the autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.] </source> \\n</s>\\n\\n</s> \\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n</s>\\n\\n</s>\\n</s>\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n</s>\\n</s>\\n</s> \\n</s>\\n\\n</s>\\n</s>\\n\\n</s>\\n</', \" truck-mounted radar subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem. 6: Initially, implementing such a system would require similar preventative maintenance and maintenance schedule similar to those required with conventional vehicle emission or fuel system control units. These maintenance schedules would be particularly complex due to the presence of numerous interconnected components and potentially a large number of electrical and mechanical components. Similarly, there is a requirement for satellite tracking and remote monitoring of the truck and the artificial intelligence (AI) for processing the data. 7: The current state of the art has characterized that traditional systems, such as such as use of radar can be difficult in certain situations. In conclusion, it is clear that it is necessary to implement such a system to address the problem of tracking and detecting, especially in lower speed moving conditions, and comply with the goals of SD. 18. **nothing**: the text is not related to SDG The text: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of an autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.]\\nAnswer:\\n<reason> The text describes a system involving a truck-mounted sensor to detect trailer-related vehicles and conditions, which relates to SDGs 8 (Decent Work and Economic Growth), 7 (Affordable and Clean Energy), and 13 (Climate Action). These goals are related to improving infrastructure and sustainable energy systems, which are covered by the content mentioned in the disclosure. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer> <reason> The text details a system where truck-mounted sensors emit electromagnetic waves to detect trailer behaviors and transfer data to a vehicle control subsystem. This relates to SDG 8 (Decent Work and Economic Growth) as it involves a system that supports efficient operations and uses sensors to enhance vehicle performance. Furthermore, SDG 7 (Affordable and Clean Energy) is mentioned as the goal of meeting the system's emissions and energy needs, while SDG 13 (Climate Action) considers the impact beyond emissions, promoting sustainable infrastructure. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer> <reason> The text describes deployment mechanisms for the truck-mounted sensors, emphasizing their use in improving infrastructure and energy access for autonomous vehicles. Relevant SDGs include 13 (Climate Action) for environmental goals, 8 (Decent Work and Economic Growth) for efficiency, and 7 (Affordable and Clean Energy) for technology deployment. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer>\\n\\nThe text talks about a system and method that involves truck-mounted sensors to detect trailer following vehicles and conditions. This relates to the goals of SDG 8, 7, and 13, as these SDGs are related to economic growth, energy access, and climate action initiatives.\\n\\n<reason> No explicit SDGs are listed, but the system description related to infrastructure support and energy efficiency, especially for autonomous vehicles, aligns with SDGs 8 (economic development and work), 7 (energy access), and 13 (climate action). </reason>\\n<sdg> 8, 7, 13 </sdg> <reason> The text is a technical documentation about a system with truck-mounted sensors for autonomous vehicles. SDGs 8, 7, and 13 are directly relevant to infrastructure, energy, and climate goals, which are most accurately represented in the system's functionality. </reason>\\n<sdg> 8, 7, 13 </sdg> <reason> The description clearly states that the system involves EM radiation to detect objects, indicating its relevance to SDG 7 (affordable and\", ' truck-mounted radar subsystem is configured to emit radio waves traveling in a certain direction from the emitter, to generate object data representing the objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem. 6: The tunnel exists at the junction between two roads. The tunnel leads to a highway, which is connected to the surrounding area of the tunnel. When driving through the tunnel, the driver must pass the tunnel. The tunnel is typically open and navigable. 7: When traffic is road-going, the vehicle does not have to move in response to the traffic signal. On the other hand, when traffic signals are not displayed, the vehicle needs to travel at a different speed. However, the problem of how much speed the vehicle should travel at, the displayed speed on the display, and the traffic flow can be difficult to manage, and thus, an optimal travel time is desired for the movement of a vehicle. 8: Also, the traffic conditions on the highway can be positively affected by weather conditions. For instance, a truly sunny day is ideal only if the sun is not blocked by any clouds. When the tunnel is open during the morning, the fog can be particularly noticeable. Fog can be seen from the headlights. 9: A processor on a vehicle is a data processor that is used for managing control of the vehicle. As the vehicle increases, the processor has to conduct an increasing number of operations. But, the increased number of operations in the processor can be difficult to manage for the vehicle. 10: The structure of a truck, or the design of a warehouse, can affect how efficiently the warehouse is designed and operated in the future. The central idea being discussed is that it is important for the future design and operation of the warehouse to consider the future needs of the business and the operations. 11: The world as a whole, except for some development areas (non-market economies), consists of people who work on developing lower level economies. In addition, the people who manage these economies can support those developing economies by providing strategic governance and direction. The idea is reflected in the management of managerial functions and the organization of the workforce. Furthermore, it is important for the people who manage these economies to advance in their own organization and to become fully capable of increasing their skills and abilities. 12: Additionally, the rear of the vehicle may have some movable pieces that may serve a purpose. For example, store shelves, display panels, beds, drug cabinets, or any other purposes a user might have. 13: Sustainable development is difficult to address in the current time. However, there is a possibility that, within the next few years, sustainable development will be achieved. 14: Originates in fossil fuels, and is also one of the possible results of the coal, oil and natural gas. 15: Determining what is sustainable means determining what can be done on a global scale, and not only in the local scope. 16: The activity of liturgy is a part of the daily life of people who perform liturgy. This activity is also a part of the life of people who perform religious activities. 17: The boat travels forward by means of the force of water. 18: The aroma of a perfume can be compared to the aroma of the perfume used. 19: As the year approaches end, people are typically monitoring their own behavior. 20: An interactive display system is used to display digital content. 21: Cello have the ability to repeat patterns. 22: Chromium and nickel have no radioactive cores. 23: Sensitivity of the human body to the light and a violet range of wavelengths is a benefit of cerulean blue. 24: Compared to water, the aqueous solubility of the substance in which it is dissolved is higher. 25: By covering the negative area of the memory on the computer. 26: ADHD is a type of both mental and emotional challenge. 27: Under statistics, an increase of small amounts of nitrogen in human blood can also be represented by the same concentration of nitrogen in blood. 28: Birth of a baby is a significant event. 29: A tree in the future will continue to grow and produce fruit. 30: The old people of the world are very old. 31: Carrying too much weight on the neck, and the location', ' truck-mounted radar subsystem is configured to emit electromagnetic waves and then to detect the movement of objects, based on an electromagnetic wave transmitted by the truck on the first pass. Thus, the truck-mounted radar can determine whether or not an object is present in the area of the truck or the trailer, as well as the movement of the objects. 6: The system described in item 5 is further implemented, as an example, by combining this truck-mounted radar with a location satellite system or an embedded GPS system. 7: The first-pass phase of radar systems utilizing GPS based or local, for example, GPS or other similar systems, provides a data transmission channel for the vehicle with the sensor to transmit the data to the vehicle control subsystem. One particular feature of such systems is that the emitted waves are in a vertical direction, which allows the emission of waves that can travel through the air and either reflect from a surface or from an object located within the space. This feature alone, such as the vertical emission direction, allows the system to sense objects with different characteristics and also allow spatial contouring. 8: The second-pass phase of radar systems utilizing GPS based or local, for example, GPS or other similar systems, provides a data transmission channel for the vehicle with the sensor to transmit the data to the vehicle control subsystem. This second-pass phase provides a reference point for the direction in which an object is reflecting off the earth\\'s surface and also provides a data point for the spatial location of the object. The use of the vertical emission of electromagnetic waves in the second-pass phase allows the system to detect objects both at sub-city level, for example, for urban. For example, if an object of greater distance, such as trucks or taller vehicles, is traveling at a high speed, then by utilizing the vertical emission in the second-pass phase, the distance can be determined as a function of the velocity of the object. 9: In the case where a vehicle is buried under drift or hazardous conditions, it is not possible to use the emissions of a truck or other non-powered equipment (drill, cable, etc.) to detect such an object without the guide of the vehicle\\'s sensors, because the vehicles themselves cannot detect such objects. 10: However, existing vehicles do not have adequate sensor systems to detect objects that come from the side of the vehicle, such as following vehicles. And the sensors do not detect the deformation or damage from the metal components of the truck. 11: It is particularly important to detect the following vehicles and trailer conditions in the view of the tractor operator when the tractor is at maximum position for operating its tasks. 12: The system described above can detect multiple objects simultaneously during the radar assessment phase. 13: The controller of the vehicle control subsystem may include a processor. 14: The system described above can be implemented in different ways. 15: The method is described in detail. 16: The invention is provided and described as an example. 17: The patent document does not mention the presence of the SDGs.\\n\\nThe user\\'s text is: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of the autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.]\\n\\n\\nSo, the assistant should classify this text into the appropriate goal [17] SDGs and/or multiple SDGs in the case of multiple. Let\\'s try it. There\\'s a reference to: \"truck-mounted sensors to detect trailer following vehicles and trailer conditions.\" Let\\'s look up the definitions of SDGs 17, which is \"Partnerships for the Goals.\" The text is talking about a technology or method that involves truck-mounted sensors, monitoring trailer conditions, and detecting following vehicles. Now, is this text related to any of the SDGs listed? \\n\\nSDG 17 is \"Partnerships for the Goals.\" The text is discussing the technical implementation of an autonomous truck and its sensors for detecting and monitoring']\n",
      "Generated rewards: [0.0, 0.0, 0.0, 0.0]\n",
      "[' truck-mounted radar subsystem is configured to emit electromagnetic waves propagating in a space under the trailer. The truck-mounted radar associated with the work described in this patent is designed for detecting objects in the space under the trailer and detecting object positions by sending a signal. 6: The configuration of the truck-mounted radar subsystem consistent with the example embodiment mentioned in the previous paragraph; the truck-mounted sensor is more accurate in detecting the objects in the area where they are observed and with the characteristics of conductivity, and adds the ability to sense objects with higher frequencies and a lower range of dust explosion and noise. However, the implementation cost for such a system is relatively high. 7: Presenters and authors contribute that the improvement in the system and method of truck-mounted sensors in this patent is significant and appropriate for use in the field of automotive engineering. 8: This patent document is exemplary in illustrating a method to detect and monitor various automotive systems, including and not limited to vehicles, asphalt, roadways, glass, and steel. 9: Regarding the problem of tractors and tractors causing an overlap in areas where they are used, such as in the traffic, and the effect of these overlapping areas on other vehicles or traffic constraints, the technical field is with the topic of this patent. 10: The issue described in this patent is related to wheelchair access, transportation, and mobility; it is not related to sustainable development goals. 11: The system and method of this patent described them; the example embodiment becomes a tractor trailer system and includes all the features described before. 12: This patent document does not distinguish between an object and a machine, nor between an object and a vehicle, and so does not provide any indication of discrimination. 13: The problem resides in the area where the electromagnetic waves leak outside. The original patent ignored this problem and cannot provide proper environmental settings for the sensor. 14: According to the patent, it describes a half-ellipse as a bluff shape for a part of the truck. The shape of the truck is the same as the shape of the half-ellipse. 15: The patent also describes a typical model, a guided guidance mode of the truck. 16: This patent does not talks about transfer or transfer notes. The text does not talk about transfer of documents or information, it discusses systems, methods of data acquisition, and the relationship between different parts of the truck-trailer system. Therefore, the text is not related to any of the SDGs specified in the list.\\nAnswer:\\n<reason> Since the text describes a system and method of truck-mounted sensors, it relates to SDG 13 (Climate Action) and SDG 12 (Responsible Consumption and Production). However, the text also mentions the problem with electromagnetic waves leaking outside the truck and the need for proper environmental settings, which relates to SDG 13. The invention involves detecting and monitoring different automotive systems, which aligns with SDG 13. The details about the sensor configurations and implementation may also relate to SDG 7 (Affordable and Clean Energy) if the sensors are used to detect and monitor energy-related objects. However, based on the provided SDGs and the specific information given, the most relevant SDGs are SDG 12 and SDG 13.</reason>\\n<sdg>12, 13</sdg>\\n</s>Source: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of the autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.] </source> \\n</s>\\n\\n</s> \\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n</s>\\n\\n</s>\\n</s>\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n\\n</s>\\n</s>\\n</s>\\n</s> \\n</s>\\n\\n</s>\\n</s>\\n\\n</s>\\n</', \" truck-mounted radar subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem. 6: Initially, implementing such a system would require similar preventative maintenance and maintenance schedule similar to those required with conventional vehicle emission or fuel system control units. These maintenance schedules would be particularly complex due to the presence of numerous interconnected components and potentially a large number of electrical and mechanical components. Similarly, there is a requirement for satellite tracking and remote monitoring of the truck and the artificial intelligence (AI) for processing the data. 7: The current state of the art has characterized that traditional systems, such as such as use of radar can be difficult in certain situations. In conclusion, it is clear that it is necessary to implement such a system to address the problem of tracking and detecting, especially in lower speed moving conditions, and comply with the goals of SD. 18. **nothing**: the text is not related to SDG The text: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of an autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.]\\nAnswer:\\n<reason> The text describes a system involving a truck-mounted sensor to detect trailer-related vehicles and conditions, which relates to SDGs 8 (Decent Work and Economic Growth), 7 (Affordable and Clean Energy), and 13 (Climate Action). These goals are related to improving infrastructure and sustainable energy systems, which are covered by the content mentioned in the disclosure. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer> <reason> The text details a system where truck-mounted sensors emit electromagnetic waves to detect trailer behaviors and transfer data to a vehicle control subsystem. This relates to SDG 8 (Decent Work and Economic Growth) as it involves a system that supports efficient operations and uses sensors to enhance vehicle performance. Furthermore, SDG 7 (Affordable and Clean Energy) is mentioned as the goal of meeting the system's emissions and energy needs, while SDG 13 (Climate Action) considers the impact beyond emissions, promoting sustainable infrastructure. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer> <reason> The text describes deployment mechanisms for the truck-mounted sensors, emphasizing their use in improving infrastructure and energy access for autonomous vehicles. Relevant SDGs include 13 (Climate Action) for environmental goals, 8 (Decent Work and Economic Growth) for efficiency, and 7 (Affordable and Clean Energy) for technology deployment. </reason>\\n<sdg> 8, 7, 13 </sdg>\\n</answer>\\n\\nThe text talks about a system and method that involves truck-mounted sensors to detect trailer following vehicles and conditions. This relates to the goals of SDG 8, 7, and 13, as these SDGs are related to economic growth, energy access, and climate action initiatives.\\n\\n<reason> No explicit SDGs are listed, but the system description related to infrastructure support and energy efficiency, especially for autonomous vehicles, aligns with SDGs 8 (economic development and work), 7 (energy access), and 13 (climate action). </reason>\\n<sdg> 8, 7, 13 </sdg> <reason> The text is a technical documentation about a system with truck-mounted sensors for autonomous vehicles. SDGs 8, 7, and 13 are directly relevant to infrastructure, energy, and climate goals, which are most accurately represented in the system's functionality. </reason>\\n<sdg> 8, 7, 13 </sdg> <reason> The description clearly states that the system involves EM radiation to detect objects, indicating its relevance to SDG 7 (affordable and\", ' truck-mounted radar subsystem is configured to emit radio waves traveling in a certain direction from the emitter, to generate object data representing the objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem. 6: The tunnel exists at the junction between two roads. The tunnel leads to a highway, which is connected to the surrounding area of the tunnel. When driving through the tunnel, the driver must pass the tunnel. The tunnel is typically open and navigable. 7: When traffic is road-going, the vehicle does not have to move in response to the traffic signal. On the other hand, when traffic signals are not displayed, the vehicle needs to travel at a different speed. However, the problem of how much speed the vehicle should travel at, the displayed speed on the display, and the traffic flow can be difficult to manage, and thus, an optimal travel time is desired for the movement of a vehicle. 8: Also, the traffic conditions on the highway can be positively affected by weather conditions. For instance, a truly sunny day is ideal only if the sun is not blocked by any clouds. When the tunnel is open during the morning, the fog can be particularly noticeable. Fog can be seen from the headlights. 9: A processor on a vehicle is a data processor that is used for managing control of the vehicle. As the vehicle increases, the processor has to conduct an increasing number of operations. But, the increased number of operations in the processor can be difficult to manage for the vehicle. 10: The structure of a truck, or the design of a warehouse, can affect how efficiently the warehouse is designed and operated in the future. The central idea being discussed is that it is important for the future design and operation of the warehouse to consider the future needs of the business and the operations. 11: The world as a whole, except for some development areas (non-market economies), consists of people who work on developing lower level economies. In addition, the people who manage these economies can support those developing economies by providing strategic governance and direction. The idea is reflected in the management of managerial functions and the organization of the workforce. Furthermore, it is important for the people who manage these economies to advance in their own organization and to become fully capable of increasing their skills and abilities. 12: Additionally, the rear of the vehicle may have some movable pieces that may serve a purpose. For example, store shelves, display panels, beds, drug cabinets, or any other purposes a user might have. 13: Sustainable development is difficult to address in the current time. However, there is a possibility that, within the next few years, sustainable development will be achieved. 14: Originates in fossil fuels, and is also one of the possible results of the coal, oil and natural gas. 15: Determining what is sustainable means determining what can be done on a global scale, and not only in the local scope. 16: The activity of liturgy is a part of the daily life of people who perform liturgy. This activity is also a part of the life of people who perform religious activities. 17: The boat travels forward by means of the force of water. 18: The aroma of a perfume can be compared to the aroma of the perfume used. 19: As the year approaches end, people are typically monitoring their own behavior. 20: An interactive display system is used to display digital content. 21: Cello have the ability to repeat patterns. 22: Chromium and nickel have no radioactive cores. 23: Sensitivity of the human body to the light and a violet range of wavelengths is a benefit of cerulean blue. 24: Compared to water, the aqueous solubility of the substance in which it is dissolved is higher. 25: By covering the negative area of the memory on the computer. 26: ADHD is a type of both mental and emotional challenge. 27: Under statistics, an increase of small amounts of nitrogen in human blood can also be represented by the same concentration of nitrogen in blood. 28: Birth of a baby is a significant event. 29: A tree in the future will continue to grow and produce fruit. 30: The old people of the world are very old. 31: Carrying too much weight on the neck, and the location', ' truck-mounted radar subsystem is configured to emit electromagnetic waves and then to detect the movement of objects, based on an electromagnetic wave transmitted by the truck on the first pass. Thus, the truck-mounted radar can determine whether or not an object is present in the area of the truck or the trailer, as well as the movement of the objects. 6: The system described in item 5 is further implemented, as an example, by combining this truck-mounted radar with a location satellite system or an embedded GPS system. 7: The first-pass phase of radar systems utilizing GPS based or local, for example, GPS or other similar systems, provides a data transmission channel for the vehicle with the sensor to transmit the data to the vehicle control subsystem. One particular feature of such systems is that the emitted waves are in a vertical direction, which allows the emission of waves that can travel through the air and either reflect from a surface or from an object located within the space. This feature alone, such as the vertical emission direction, allows the system to sense objects with different characteristics and also allow spatial contouring. 8: The second-pass phase of radar systems utilizing GPS based or local, for example, GPS or other similar systems, provides a data transmission channel for the vehicle with the sensor to transmit the data to the vehicle control subsystem. This second-pass phase provides a reference point for the direction in which an object is reflecting off the earth\\'s surface and also provides a data point for the spatial location of the object. The use of the vertical emission of electromagnetic waves in the second-pass phase allows the system to detect objects both at sub-city level, for example, for urban. For example, if an object of greater distance, such as trucks or taller vehicles, is traveling at a high speed, then by utilizing the vertical emission in the second-pass phase, the distance can be determined as a function of the velocity of the object. 9: In the case where a vehicle is buried under drift or hazardous conditions, it is not possible to use the emissions of a truck or other non-powered equipment (drill, cable, etc.) to detect such an object without the guide of the vehicle\\'s sensors, because the vehicles themselves cannot detect such objects. 10: However, existing vehicles do not have adequate sensor systems to detect objects that come from the side of the vehicle, such as following vehicles. And the sensors do not detect the deformation or damage from the metal components of the truck. 11: It is particularly important to detect the following vehicles and trailer conditions in the view of the tractor operator when the tractor is at maximum position for operating its tasks. 12: The system described above can detect multiple objects simultaneously during the radar assessment phase. 13: The controller of the vehicle control subsystem may include a processor. 14: The system described above can be implemented in different ways. 15: The method is described in detail. 16: The invention is provided and described as an example. 17: The patent document does not mention the presence of the SDGs.\\n\\nThe user\\'s text is: [A system and method providing truck-mounted sensors to detect trailer following vehicles and trailer conditions are disclosed. A system of an example embodiment comprises: a vehicle control subsystem installed in an autonomous truck, the vehicle control subsystem comprising a data processor; and a truck-mounted sensor subsystem installed on a portion of a tractor of the autonomous truck to which a trailer is attachable, the truck-mounted sensor subsystem being coupled to the vehicle control subsystem via a data connection, wherein the truck-mounted sensor subsystem is configured to emit electromagnetic waves propagating in a space under the trailer, to generate object data representing objects detected by receiving a reflection of the electromagnetic waves, and to transfer the object data to the vehicle control subsystem.]\\n\\n\\nSo, the assistant should classify this text into the appropriate goal [17] SDGs and/or multiple SDGs in the case of multiple. Let\\'s try it. There\\'s a reference to: \"truck-mounted sensors to detect trailer following vehicles and trailer conditions.\" Let\\'s look up the definitions of SDGs 17, which is \"Partnerships for the Goals.\" The text is talking about a technology or method that involves truck-mounted sensors, monitoring trailer conditions, and detecting following vehicles. Now, is this text related to any of the SDGs listed? \\n\\nSDG 17 is \"Partnerships for the Goals.\" The text is discussing the technical implementation of an autonomous truck and its sensors for detecting and monitoring']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRPOTrainer\n\u001b[32m      3\u001b[39m trainer = GRPOTrainer(\n\u001b[32m      4\u001b[39m     model=model, processing_class = tokenizer, reward_funcs=[format_reward, accuracy_reward], args=training_args, train_dataset=train_dataset\n\u001b[32m      5\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/epo-code-fest-spring-2025/backend/notebooks/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:314\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:25\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/project/epo-code-fest-spring-2025/backend/notebooks/unsloth_compiled_cache/UnslothGRPOTrainer.py:1034\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._prepare_inputs\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m   1032\u001b[39m         keys = [key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m inputs[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m   1033\u001b[39m         reward_kwargs = {key: [example[key] \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m inputs] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys}\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         output_reward_func = \u001b[43mreward_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mreward_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m         rewards_per_func[:, i] = torch.tensor(output_reward_func, dtype=torch.float32, device=device)\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m# Gather the reward per function: this part is crucial, because the rewards are normalized per group and the\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m# completions may be distributed across processes\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36maccuracy_reward\u001b[39m\u001b[34m(completions, **kwargs)\u001b[39m\n\u001b[32m      3\u001b[39m sdg_tag_solutions = kwargs[\u001b[33m\"\u001b[39m\u001b[33msolution\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(completions)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m completion_contents = [\u001b[43mcompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m completion \u001b[38;5;129;01min\u001b[39;00m completions]\n\u001b[32m      6\u001b[39m rewards = []\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m content, sdg_tag_solution \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(completion_contents, sdg_tag_solutions):\n",
      "\u001b[31mTypeError\u001b[39m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "from trl import GRPOTrainer\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model, processing_class = tokenizer, reward_funcs=[format_reward, accuracy_reward], args=training_args, train_dataset=train_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3289801",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
