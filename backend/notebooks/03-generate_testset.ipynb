{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83665d82",
   "metadata": {},
   "source": [
    "# Generate Test Set\n",
    "\n",
    "In this notebook, we generate a test set using model version v0.1.0. The goal is to create a representative and balanced dataset. To achieve this, we classify a large number of patents, shuffle the results, and then sample a few instances from each class. Finally, we manually verify and correct the labels for each class to ensure accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6518816",
   "metadata": {},
   "source": [
    "## Step 1: Generate Initial Predictions\n",
    "\n",
    "We classify all patents using the model from `02-classify_patent_v0.1.0.ipynb`.  \n",
    "For each patent description, we store the following information:\n",
    "\n",
    "- `num_patent`: Patent number  \n",
    "- `num_desc`: Description number  \n",
    "- `desc`: Patent description text  \n",
    "- `sdg_pred`: Predicted SDG (Sustainable Development Goal) class\n",
    "\n",
    "The results are saved in `classified_patents_raw.jsonl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb241012",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 1.1. Load all Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc64056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa974b4fabe48bd9e4cc90f51b3df06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching patent numbers by batch:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number = get_all_patents_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf55bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total patents: 23337\n",
      "Total patent numbers collected: 23337\n",
      "Retrieved unique patent numbers: 23337\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compare and report the result\n",
    "patents_metadata = get_all_patents()\n",
    "total_expected = patents_metadata.total_count\n",
    "\n",
    "print(f\"Expected total patents: {total_expected}\")\n",
    "print(f\"Total patent numbers collected: {len(all_patents_number)}\")\n",
    "print(f\"Retrieved unique patent numbers: {len(list(set(all_patents_number)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bfb9e",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 1.2. Analyse patents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e98f1",
   "metadata": {},
   "source": [
    "#### 1.2.1. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a8ed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from api.config.ai_config import ai_huggingface_token\n",
    "from api.models.Patent import FullPatent\n",
    "from api.repositories.patent_repository import update_full_patent\n",
    "\n",
    "# Dict of SDG candidate labels\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}\n",
    "\n",
    "candidate_label_values = list(sdg_labels_dict.values())\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\", token=ai_huggingface_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc9169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdg_code_from_label(label: str, label_dict: dict) -> str:\n",
    "    \"\"\"Reverse lookup SDG code from full label text.\"\"\"\n",
    "    for code, text in label_dict.items():\n",
    "        if label == text:\n",
    "            return code\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "def classify_full_patent_description(patent: FullPatent,\n",
    "                                     classifier=classifier,\n",
    "                                     candidate_labels=candidate_label_values,\n",
    "                                     label_dict=sdg_labels_dict,\n",
    "                                     treshold: float = 0.18) -> FullPatent:\n",
    "    \"\"\"\n",
    "    Classify all description blocks in a FullPatent and enrich them with SDG labels.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent to analyze.\n",
    "        classifier: HuggingFace classifier.\n",
    "        candidate_labels (list): SDG label texts.\n",
    "        label_dict (dict): Map from SDG label text to SDG code.\n",
    "        treshold (float): Minimum score to accept prediction.\n",
    "\n",
    "    Returns:\n",
    "        FullPatent: Enriched object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Filter descriptions with enough length\n",
    "    valid_descriptions = [(desc, desc.description_text) \n",
    "                          for desc in patent.description \n",
    "                          if len(desc.description_text.split()) > 20]\n",
    "\n",
    "    # Step 2: Extract just the text for classification\n",
    "    texts_to_classify = [text for _, text in valid_descriptions]\n",
    "\n",
    "    # Step 3: Run classifier on batch\n",
    "    results = classifier(texts_to_classify, candidate_labels=candidate_labels)\n",
    "\n",
    "    # Step 4: Assign results back to descriptions\n",
    "    for (desc, _), result in zip(valid_descriptions, results):\n",
    "\n",
    "        try:\n",
    "            top_score = result[\"scores\"][0]\n",
    "            if top_score >= treshold:\n",
    "                label_text = result[\"labels\"][0]\n",
    "                desc.sdg = get_sdg_code_from_label(label_text, label_dict)\n",
    "            else:\n",
    "                desc.sdg = \"None\"\n",
    "                top_score = -1\n",
    "\n",
    "            # print(f\"[{desc.description_number}] Label: {desc.sdg} | Score: {top_score:.3f} | Text: {desc.description_text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error on description {desc.description_number}: {e}\")\n",
    "            desc.sdg = \"Error\"\n",
    "\n",
    "    # Step 5: Handle short descriptions (not classified)\n",
    "    for desc in patent.description:\n",
    "        if len(desc.description_text.split()) <= 20:\n",
    "            desc.sdg = \"None\"\n",
    "\n",
    "    patent.is_analyzed = True\n",
    "\n",
    "    # Update the Patent in Database\n",
    "    update_full_patent(patent.model_dump())\n",
    "\n",
    "    return patent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc948a",
   "metadata": {},
   "source": [
    "#### 1.2.2. Run analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cceb8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "\n",
    "def load_already_classified_patents(file_path: str) -> set:\n",
    "    \"\"\"Charge les brevets dÃ©jÃ  enregistrÃ©s dans le fichier JSONL.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "\n",
    "    classified = set()\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                classified.add(item[\"patent_number\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading line: {e}\")\n",
    "    return classified\n",
    "\n",
    "\n",
    "def save_classified_descriptions(data: List[Dict], file_path: str):\n",
    "    \"\"\"Ajoute les nouvelles descriptions Ã  la fin du fichier JSONL.\"\"\"\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def analyze_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"../src/ai/testsets/raw/classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "    random.shuffle(to_process)\n",
    "\n",
    "    for patent_number in to_process:\n",
    "        try:\n",
    "            print(f\"\\nProcessing patent {patent_number}...\")\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            enriched_patent = classify_full_patent_description(patent)\n",
    "\n",
    "            output_data = []\n",
    "            for desc in enriched_patent.description:\n",
    "                output_data.append({\n",
    "                    \"patent_number\": patent_number,\n",
    "                    \"description_number\": desc.description_number,\n",
    "                    \"description_text\": desc.description_text,\n",
    "                    \"sdg\": desc.sdg\n",
    "                })\n",
    "\n",
    "            save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231a42de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patents to process: 23337\n",
      "\n",
      "Processing patent EP4052567A1...\n",
      "\n",
      "Processing patent EP4239077A2...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Analyse all patents\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43manalyze_patents_and_save_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_patents_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../src/ai/testsets/raw/classified_patents_raw.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36manalyze_patents_and_save_descriptions\u001b[39m\u001b[34m(patent_numbers, export_file)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mProcessing patent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatent_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m patent = get_full_patent_by_number(patent_number)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m enriched_patent = \u001b[43mclassify_full_patent_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m output_data = []\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m desc \u001b[38;5;129;01min\u001b[39;00m enriched_patent.description:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mclassify_full_patent_description\u001b[39m\u001b[34m(patent, classifier, candidate_labels, label_dict, treshold)\u001b[39m\n\u001b[32m     34\u001b[39m texts_to_classify = [text \u001b[38;5;28;01mfor\u001b[39;00m _, text \u001b[38;5;129;01min\u001b[39;00m valid_descriptions]\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Step 3: Run classifier on batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m results = \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_to_classify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Step 4: Assign results back to descriptions\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (desc, _), result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(valid_descriptions, results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:206\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__call__\u001b[39m\u001b[34m(self, sequences, *args, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1360\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[32m   1357\u001b[39m     final_iterator = \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   1358\u001b[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[32m   1359\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m     outputs = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[39m, in \u001b[36mPipelineIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_item()\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m item = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m processed = \u001b[38;5;28mself\u001b[39m.infer(item, **\u001b[38;5;28mself\u001b[39m.params)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:269\u001b[39m, in \u001b[36mPipelinePackIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     processed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch.Tensor):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:229\u001b[39m, in \u001b[36mZeroShotClassificationPipeline._forward\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect.signature(model_forward).parameters.keys():\n\u001b[32m    228\u001b[39m     model_inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m model_outputs = {\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_label\u001b[39m\u001b[33m\"\u001b[39m: candidate_label,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msequence\u001b[39m\u001b[33m\"\u001b[39m: sequence,\n\u001b[32m    234\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m: inputs[\u001b[33m\"\u001b[39m\u001b[33mis_last\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    235\u001b[39m     **outputs,\n\u001b[32m    236\u001b[39m }\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1775\u001b[39m, in \u001b[36mBartForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1772\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1773\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1776\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[32m   1793\u001b[39m eos_mask = input_ids.eq(\u001b[38;5;28mself\u001b[39m.config.eos_token_id).to(hidden_states.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1533\u001b[39m, in \u001b[36mBartModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1526\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1527\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1528\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1529\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1530\u001b[39m     )\n\u001b[32m   1532\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1378\u001b[39m, in \u001b[36mBartDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1365\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m   1366\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m   1367\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1375\u001b[39m         use_cache,\n\u001b[32m   1376\u001b[39m     )\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1391\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:664\u001b[39m, in \u001b[36mBartDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    662\u001b[39m self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    663\u001b[39m \u001b[38;5;66;03m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    671\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    672\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:516\u001b[39m, in \u001b[36mBartSdpaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[38;5;66;03m# partitioned across GPUs when using tensor-parallelism.\u001b[39;00m\n\u001b[32m    514\u001b[39m attn_output = attn_output.reshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m.embed_dim)\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Patrice\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Analyse all patents\n",
    "analyze_patents_and_save_descriptions(all_patents_number, export_file=\"../src/ai/testsets/raw/classified_patents_raw.jsonl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7f525",
   "metadata": {},
   "source": [
    "#### 1.2.3. Remove Duplicates\n",
    "\n",
    "To ensure the quality of the dataset, we remove duplicate entries (doublons) from the classified results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "376a14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 291654\n",
      "Duplicate (patent_number, description_text) pairs: 10664\n",
      "Unique (patent_number, description_text) pairs saved: 280990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(291654,\n",
       " 10664,\n",
       " ['EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4434779A1',\n",
       "  'EP4438582A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4443476A1',\n",
       "  'EP4462320A2',\n",
       "  'EP4462320A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4467184A2',\n",
       "  'EP4471684A2',\n",
       "  'EP4471684A2',\n",
       "  'EP4471684A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4472153A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477125A2',\n",
       "  'EP4477325A2',\n",
       "  'EP4477325A2',\n",
       "  'EP4477325A2',\n",
       "  'EP4477398A2',\n",
       "  'EP4482090A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4482190A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4514061A2',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516089A1',\n",
       "  'EP4516268A1',\n",
       "  'EP4516339A1',\n",
       "  'EP4516352A2',\n",
       "  'EP4516352A2',\n",
       "  'EP4516352A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516356A2',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516366A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516423A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516452A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516571A1',\n",
       "  'EP4516577A1',\n",
       "  'EP4516577A1',\n",
       "  'EP4516577A1',\n",
       "  'EP4516577A1',\n",
       "  'EP4516598A1',\n",
       "  'EP4516598A1',\n",
       "  'EP4516757A2',\n",
       "  'EP4516757A2',\n",
       "  'EP4516757A2',\n",
       "  'EP4516757A2',\n",
       "  'EP4516811A2',\n",
       "  'EP4517038A1',\n",
       "  'EP4517050A1',\n",
       "  'EP4517050A1',\n",
       "  'EP4517050A1',\n",
       "  'EP4517050A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517106A1',\n",
       "  'EP4517109A1',\n",
       "  'EP4517123A1',\n",
       "  'EP4517123A1',\n",
       "  'EP4517129A1',\n",
       "  'EP4517129A1',\n",
       "  'EP4517151A2',\n",
       "  'EP4517180A1',\n",
       "  'EP4517227A2',\n",
       "  'EP4517232A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517268A1',\n",
       "  'EP4517324A1',\n",
       "  'EP4517324A1',\n",
       "  'EP4517347A1',\n",
       "  'EP4517347A1',\n",
       "  'EP4517347A1',\n",
       "  'EP4517367A1',\n",
       "  'EP4517428A1',\n",
       "  'EP4517428A1',\n",
       "  'EP4517428A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517470A1',\n",
       "  'EP4517495A1',\n",
       "  'EP4517495A1',\n",
       "  'EP4517496A1',\n",
       "  'EP4517507A1',\n",
       "  'EP4517507A1',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517654A2',\n",
       "  'EP4517693A2',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517745A1',\n",
       "  'EP4517747A2',\n",
       "  'EP4517821A1',\n",
       "  'EP4517824A1',\n",
       "  'EP4517824A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517858A1',\n",
       "  'EP4517859A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517869A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517872A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517881A1',\n",
       "  'EP4517896A2',\n",
       "  'EP4517972A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4517996A1',\n",
       "  'EP4518022A2',\n",
       "  'EP4518022A2',\n",
       "  'EP4518022A2',\n",
       "  'EP4518022A2',\n",
       "  'EP4518060A1',\n",
       "  'EP4518060A1',\n",
       "  'EP4518060A1',\n",
       "  'EP4518066A1',\n",
       "  'EP4518066A1',\n",
       "  'EP4518091A1',\n",
       "  'EP4518182A1',\n",
       "  'EP4518182A1',\n",
       "  'EP4518251A1',\n",
       "  'EP4518251A1',\n",
       "  'EP4518251A1',\n",
       "  'EP4518251A1',\n",
       "  'EP4518251A1',\n",
       "  'EP4518259A1',\n",
       "  'EP4518259A1',\n",
       "  'EP4518259A1',\n",
       "  'EP4518259A1',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518372A2',\n",
       "  'EP4518457A1',\n",
       "  'EP4518457A1',\n",
       "  'EP4518457A1',\n",
       "  'EP4518457A1',\n",
       "  'EP4518457A1',\n",
       "  'EP4518571A2',\n",
       "  'EP4518578A2',\n",
       "  'EP4518578A2',\n",
       "  'EP4518586A1',\n",
       "  'EP4518586A1',\n",
       "  'EP4518586A1',\n",
       "  'EP4518586A1',\n",
       "  'EP4270171A2',\n",
       "  'EP4270171A2',\n",
       "  'EP4270171A2',\n",
       "  'EP4283615A2',\n",
       "  'EP4331620A2',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4362456A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4366119A1',\n",
       "  'EP4414727A1',\n",
       "  'EP4414727A1',\n",
       "  'EP4418274A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4420522A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4422344A2',\n",
       "  'EP4424376A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4427810A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  'EP4428798A2',\n",
       "  ...])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def analyze_and_save_clean_jsonl(file_path, output_path):\n",
    "    seen_pairs = set()\n",
    "    total_lines = 0\n",
    "    duplicate_lines = 0\n",
    "    duplicate_patents = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            try:\n",
    "                total_lines += 1\n",
    "                item = json.loads(line.strip())\n",
    "                pair = (item.get(\"description_text\"))\n",
    "\n",
    "                if pair in seen_pairs:\n",
    "                    duplicate_lines += 1\n",
    "                    duplicate_patents.append(item.get(\"patent_number\"))\n",
    "                else:\n",
    "                    seen_pairs.add(pair)\n",
    "                    outfile.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "    print(f\"Duplicate (patent_number, description_text) pairs: {duplicate_lines}\")\n",
    "    print(f\"Unique (patent_number, description_text) pairs saved: {len(seen_pairs)}\")\n",
    "\n",
    "    return total_lines, duplicate_lines, duplicate_patents\n",
    "\n",
    "\n",
    "input_path = \"../src/ai/testsets/raw/classified_patents_raw.jsonl\"\n",
    "output_path = \"../src/ai/testsets/raw/classified_patents_raw_clean.jsonl\"\n",
    "analyze_and_save_clean_jsonl(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff7b21",
   "metadata": {},
   "source": [
    "#### 1.2.4. Check if duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e943a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 280990\n",
      "Duplicate (patent_number, description_number) pairs: 0\n",
      "Unique (patent_number, description_number) pairs: 280990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(280990, 0, [])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_jsonl_by_patent_and_description(file_path):\n",
    "    seen_pairs = set()\n",
    "    total_lines = 0\n",
    "    duplicate_lines = 0\n",
    "    duplicate_patents = []\n",
    "\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                total_lines += 1\n",
    "                item = json.loads(line.strip())\n",
    "                pair = (item.get(\"description_text\"))\n",
    "\n",
    "                if pair in seen_pairs:\n",
    "                    duplicate_lines += 1\n",
    "                    duplicate_patents.append(item.get(\"patent_number\"))\n",
    "                else:\n",
    "                    seen_pairs.add(pair)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "    print(f\"Duplicate (patent_number, description_number) pairs: {duplicate_lines}\")\n",
    "    print(f\"Unique (patent_number, description_number) pairs: {len(seen_pairs)}\")\n",
    "\n",
    "    return total_lines, duplicate_lines, duplicate_patents\n",
    "\n",
    "# Exemple d'utilisation\n",
    "analyze_jsonl_by_patent_and_description('../src/ai/testsets/raw/classified_patents_raw_clean.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca4ea8",
   "metadata": {},
   "source": [
    "## Step 2 â€“ Create a balanced test set\n",
    "\n",
    "To ensure class balance:\n",
    "- Group data by `sdg_pred`\n",
    "- Shuffle each group\n",
    "- Sample 10 items per class\n",
    "\n",
    "The selected items are saved in testset_[version]_[language].jsonl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1fe20",
   "metadata": {},
   "source": [
    "#### 1.3.1. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19e06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from typing import List\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0  # RÃ©sultats reproductibles\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang in {\"fr\", \"en\", \"de\"}:\n",
    "            return lang\n",
    "    except LangDetectException:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def generate_classified_patents_raw(\n",
    "    jsonl_file: str,\n",
    "    version: str = \"v0\",\n",
    "    max_per_sdg: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimized: Detect language once per unique patent_number, applied to all its entries.\n",
    "    Also prints statistics per SDG.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Group items by patent_number (to ensure uniqueness and batch language detection)\n",
    "    items_by_patent = defaultdict(list)\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                patent_number = item.get(\"patent_number\")\n",
    "                if patent_number:\n",
    "                    items_by_patent[patent_number].append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    # 2. Detect language once per patent_number, then group items by language and SDG\n",
    "    grouped_by_lang = {\n",
    "        \"fr\": defaultdict(list),\n",
    "        \"en\": defaultdict(list),\n",
    "        \"de\": defaultdict(list)\n",
    "    }\n",
    "\n",
    "    for patent_number, items in items_by_patent.items():\n",
    "        # Find first non-empty description text to detect language\n",
    "        for item in items:\n",
    "            text = item.get(\"description_text\", \"\").strip()\n",
    "            if text:\n",
    "                lang = detect_language(text)\n",
    "                break\n",
    "        else:\n",
    "            lang = None\n",
    "\n",
    "        # If language detected and supported, group items by SDG under that language\n",
    "        if lang in grouped_by_lang:\n",
    "            for item in items:\n",
    "                sdg = item.get(\"sdg\")\n",
    "                if sdg is not None:\n",
    "                    grouped_by_lang[lang][sdg].append(item)\n",
    "\n",
    "    # 3. For each language, shuffle and select up to max_per_sdg items per SDG, then write to file\n",
    "    for lang, grouped in grouped_by_lang.items():\n",
    "        testset: List[dict] = []\n",
    "        per_class_count = {}\n",
    "        for sdg, items in grouped.items():\n",
    "            random.shuffle(items)\n",
    "            selected = items[:max_per_sdg]\n",
    "            testset.extend(selected)\n",
    "            per_class_count[sdg] = len(selected)\n",
    "\n",
    "        output_file = f\"../src/ai/testsets/raw/testset_{version}_{lang}_raw.jsonl\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "            for item in testset:\n",
    "                out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "        print(f\"\\n{output_file} gÃ©nÃ©rÃ© avec {len(testset)} Ã©lÃ©ments.\")\n",
    "        print(\"RÃ©partition par SDG :\")\n",
    "        for sdg in sorted(per_class_count):\n",
    "            print(f\"  SDG {sdg:>2}: {per_class_count[sdg]} Ã©lÃ©ments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e6f3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../src/ai/testsets/raw/testset_v1_fr_raw.jsonl gÃ©nÃ©rÃ© avec 0 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n",
      "\n",
      "../src/ai/testsets/raw/testset_v1_en_raw.jsonl gÃ©nÃ©rÃ© avec 0 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n",
      "\n",
      "../src/ai/testsets/raw/testset_v1_de_raw.jsonl gÃ©nÃ©rÃ© avec 42 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n",
      "  SDG None: 42 Ã©lÃ©ments\n"
     ]
    }
   ],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"../src/ai/testsets/raw/classified_patents_raw_clean.jsonl\", version=\"v1\", max_per_sdg=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035af862",
   "metadata": {},
   "source": [
    "#### 1.3.2. Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e2fdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def trouver_doublons_jsonl(fichier_jsonl):\n",
    "    \"\"\"\n",
    "    Find duplicates in a JSONL file based on 'patent_number' and 'description_text'.\n",
    "\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: List of duplicate entries (each as a dictionary).\n",
    "    \"\"\"\n",
    "    vus = defaultdict(list)\n",
    "    doublons = []\n",
    "\n",
    "    with open(fichier_jsonl, 'r', encoding='utf-8') as f:\n",
    "        for ligne in f:\n",
    "            try:\n",
    "                item = json.loads(ligne.strip())\n",
    "                cle = (item.get('description_text'))\n",
    "                vus[cle].append(item)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped line due to parsing error : {e}\")\n",
    "\n",
    "    for items in vus.values():\n",
    "        if len(items) > 1:\n",
    "            doublons.extend(items)\n",
    "\n",
    "    return doublons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca319778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_v1_en_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88c0d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_v1_fr_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e86fa522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_v1_de_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850b6c4",
   "metadata": {},
   "source": [
    "## Optional Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a14832",
   "metadata": {},
   "source": [
    "### Retrieve all patent numbers from the database\n",
    "\n",
    "If you want to retrieve the labeled data from the database instead of regenerating it, you can use the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a2fe440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60a2655d8b044c2b5bfe4f351efffa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching patent numbers by batch:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number_if_analysed():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            if patent.is_analyzed:\n",
    "                all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number_if_analysed = get_all_patents_number_if_analysed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267f1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def db_get_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"../src/ai/testsets/raw/classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "\n",
    "\n",
    "    for patent_number in tqdm(to_process, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            # If analysed patent save it\n",
    "            if patent.is_analyzed:\n",
    "                output_data = []\n",
    "                for desc in patent.description:\n",
    "                    output_data.append({\n",
    "                        \"patent_number\": patent_number,\n",
    "                        \"description_number\": desc.description_number,\n",
    "                        \"description_text\": desc.description_text,\n",
    "                        \"sdg\": desc.sdg\n",
    "                    })\n",
    "\n",
    "                save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab86d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patents to process: 2478\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66abb79de1be44d8966329194503d5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patent recovered:   0%|          | 0/2478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdb_get_patents_and_save_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_patents_number_if_analysed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../src/ai/testsets/raw/classified_patents_raw_db.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mdb_get_patents_and_save_descriptions\u001b[39m\u001b[34m(patent_numbers, export_file)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m patent_number \u001b[38;5;129;01min\u001b[39;00m tqdm(to_process, desc=\u001b[33m\"\u001b[39m\u001b[33mPatent recovered\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         patent = \u001b[43mget_full_patent_by_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatent_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# If analysed patent save it\u001b[39;00m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m patent.is_analyzed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\src\\api\\services\\patent_service.py:60\u001b[39m, in \u001b[36mget_full_patent_by_number\u001b[39m\u001b[34m(patent_number)\u001b[39m\n\u001b[32m     57\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieving full patent by number: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatent_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Call the repository function to get the full patent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m full_patent_data = \u001b[43mpatent_repository\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_full_patent_by_number\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatent_number\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_patent_data:\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FullPatent(**full_patent_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Projets\\CodeFest_2025\\epo-code-fest-spring-2025\\backend\\src\\api\\repositories\\patent_repository.py:255\u001b[39m, in \u001b[36mget_full_patent_by_number\u001b[39m\u001b[34m(number)\u001b[39m\n\u001b[32m    249\u001b[39m fetch_description_query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[33mSELECT description_number, description_text, patent_number, sdg\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[33mFROM patent_description\u001b[39m\n\u001b[32m    252\u001b[39m \u001b[33mWHERE patent_number = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m;\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    254\u001b[39m cursor = conn.cursor()\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetch_description_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m descriptions = cursor.fetchall()\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m description \u001b[38;5;129;01min\u001b[39;00m descriptions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\utf_8.py:15\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(input, errors)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[32m     13\u001b[39m encode = codecs.utf_8_encode\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.utf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIncrementalEncoder\u001b[39;00m(codecs.IncrementalEncoder):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "db_get_patents_and_save_descriptions(all_patents_number_if_analysed, export_file=\"../src/ai/testsets/raw/classified_patents_raw_db.jsonl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d619e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 474\n",
      "Duplicate (patent_number, description_text) pairs: 24\n",
      "Unique (patent_number, description_text) pairs saved: 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(474,\n",
       " 24,\n",
       " ['EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4425089A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1',\n",
       "  'EP4432545A1'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Remove duplicates\n",
    "input_path = \"../src/ai/testsets/raw/classified_patents_raw_db.jsonl\"\n",
    "output_path = \"../src/ai/testsets/raw/classified_patents_raw_db_clean.jsonl\"\n",
    "analyze_and_save_clean_jsonl(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1d2fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines: 42\n",
      "Duplicate (patent_number, description_number) pairs: 0\n",
      "Unique (patent_number, description_number) pairs: 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(42, 0, [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_jsonl_by_patent_and_description('../src/ai/testsets/raw/classified_patents_raw_clean.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de9ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../src/ai/testsets/raw/testset_db_v1_fr_raw.jsonl gÃ©nÃ©rÃ© avec 0 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n",
      "\n",
      "../src/ai/testsets/raw/testset_db_v1_en_raw.jsonl gÃ©nÃ©rÃ© avec 23 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n",
      "  SDG None: 10 Ã©lÃ©ments\n",
      "  SDG SDG10: 1 Ã©lÃ©ments\n",
      "  SDG SDG12: 10 Ã©lÃ©ments\n",
      "  SDG SDG4: 1 Ã©lÃ©ments\n",
      "  SDG SDG9: 1 Ã©lÃ©ments\n",
      "\n",
      "../src/ai/testsets/raw/testset_db_v1_de_raw.jsonl gÃ©nÃ©rÃ© avec 0 Ã©lÃ©ments.\n",
      "RÃ©partition par SDG :\n"
     ]
    }
   ],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"../src/ai/testsets/raw/classified_patents_raw_db_clean.jsonl\", version=\"db_v1\", max_per_sdg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29e67a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_db_v1_en_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa0798b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_db_v1_fr_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "177351d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"../src/ai/testsets/raw/testset_db_v1_de_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adca1f",
   "metadata": {},
   "source": [
    "### Generate SDG justification summaries for a FullPatent.\n",
    "\n",
    "This function allows you to generate summary justifications for the patents that have already been classified. These summaries can then be used to update the database, ensuring that the front-end displays the most up-to-date and relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0cbe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.models.Patent import FullPatent\n",
    "from api.models.SDGSummary import SDGSummary\n",
    "\n",
    "def generate_summary(patent: FullPatent,\n",
    "                     ai_client,\n",
    "                     ai_model: str,\n",
    "                     sdg_labels_dict: dict) -> list[SDGSummary]:\n",
    "    \"\"\"\n",
    "    Generate SDG justification summaries for a FullPatent.\n",
    "\n",
    "    This function groups description blocks by their assigned SDG labels \n",
    "    (excluding \"None\" or \"Error\"), then uses an AI model to generate a \n",
    "    summary explaining how the content supports the respective SDG.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent object containing the description blocks.\n",
    "        ai_client: AI client used to generate summaries.\n",
    "        ai_model (str): The identifier of the AI model to be used.\n",
    "        sdg_labels_dict (dict): Mapping from SDG codes to their textual descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list[SDGSummary]: A list of SDGSummary objects created for the patent.\n",
    "    \"\"\"\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    # Group descriptions by SDG label, excluding \"None\" and \"Error\"\n",
    "    sdg_to_descriptions = {}\n",
    "    for desc in patent.description:\n",
    "        if desc.sdg not in [\"None\", \"Error\"]:\n",
    "            sdg_to_descriptions.setdefault(desc.sdg, []).append(desc)\n",
    "\n",
    "    for sdg_code, descriptions in tqdm(sdg_to_descriptions.items(), desc=f\"Generating summaries for patent {patent.number}\"):\n",
    "        try:\n",
    "            sdg_description = sdg_labels_dict[sdg_code]\n",
    "            combined_text = \"\\n\".join(desc.description_text for desc in descriptions)\n",
    "\n",
    "            system_prompt = f\"\"\"\n",
    "            You are an AI specialized in sustainable development and patents. Read the following patent excerpt and explain how it contributes to this Sustainable Development Goal (SDG): {sdg_code} - {sdg_description}.\n",
    "\n",
    "            Focus on:\n",
    "            - The main innovation or idea in the patent.\n",
    "            - How it supports the targets of the SDG.\n",
    "            - Any positive impact (social, environmental, or economic) it may have.\n",
    "\n",
    "            Patent text:\n",
    "            {combined_text}\n",
    "\n",
    "            Write a short, clear summary showing the link between the patent and the SDG.\n",
    "            \"\"\"\n",
    "\n",
    "            user_prompt = f\"\"\"\n",
    "            Summarize how this patent helps achieve the SDG: {sdg_code} - {sdg_description}.\"\"\"\n",
    "\n",
    "            response = ai_client.chat(\n",
    "                model=ai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}],\n",
    "                options = {\"num_predict\":512}\n",
    "            )\n",
    "\n",
    "            summary_text = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            summary = SDGSummary(\n",
    "                patent_number=str(patent.number),\n",
    "                sdg=str(sdg_code),\n",
    "                sdg_description=summary_text\n",
    "            )\n",
    "\n",
    "            summaries.append(summary)\n",
    "\n",
    "            # print(f\"[{patent.number}] SDG: {sdg_code} | Summary:\\n{summary_text}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary for SDG {sdg_code} in patent {patent.number}: {e}\")\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46402363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.repositories.sdg_summary_repository import get_sdg_summary_by_patent_number\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "from api.repositories.sdg_summary_repository import create_sdg_summary\n",
    "from api.config.ai_config import ai_model, ai_client\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_summaries_for_patent_in_db_analysed(patent_numbers: List[str]):\n",
    "\n",
    "    for patent_number in tqdm(patent_numbers, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            # We check if a summary already exists\n",
    "            summaries = get_sdg_summary_by_patent_number(patent_number)\n",
    "\n",
    "            if not summaries:\n",
    "                patent = get_full_patent_by_number(patent_number)\n",
    "                summaries = generate_summary(patent, ai_client, ai_model, sdg_labels_dict)\n",
    "                \n",
    "                # Save in bdd\n",
    "                for summary in summaries:\n",
    "                    create_sdg_summary(summary.model_dump())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and summaries generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_summaries_for_patent_in_db_analysed(all_patents_number_if_analysed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
