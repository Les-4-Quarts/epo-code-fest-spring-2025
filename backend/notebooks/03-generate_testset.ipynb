{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83665d82",
   "metadata": {},
   "source": [
    "# Generate Test Set\n",
    "\n",
    "In this notebook, we generate a test set using model version v0.1.0. The goal is to create a representative and balanced dataset. To achieve this, we classify a large number of patents, shuffle the results, and then sample a few instances from each class. Finally, we manually verify and correct the labels for each class to ensure accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6518816",
   "metadata": {},
   "source": [
    "## Step 1: Generate Initial Predictions\n",
    "\n",
    "We classify all patents using the model from `02-classify_patent_v0.1.0.ipynb`.  \n",
    "For each patent description, we store the following information:\n",
    "\n",
    "- `num_patent`: Patent number  \n",
    "- `num_desc`: Description number  \n",
    "- `desc`: Patent description text  \n",
    "- `sdg_pred`: Predicted SDG (Sustainable Development Goal) class\n",
    "\n",
    "The results are saved in `classified_patents_raw.jsonl`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb241012",
   "metadata": {},
   "source": [
    "### üîπ Step 1.1. Load all Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number = get_all_patents_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf55bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare and report the result\n",
    "patents_metadata = get_all_patents()\n",
    "total_expected = patents_metadata.total_count\n",
    "\n",
    "print(f\"Expected total patents: {total_expected}\")\n",
    "print(f\"Total patent numbers collected: {len(all_patents_number)}\")\n",
    "print(f\"Retrieved unique patent numbers: {len(list(set(all_patents_number)))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1bfb9e",
   "metadata": {},
   "source": [
    "### üîπ Step 1.2. Analyse patents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e98f1",
   "metadata": {},
   "source": [
    "#### 1.2.1. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from transformers import pipeline\n",
    "from api.config.ai_config import ai_huggingface_token\n",
    "from api.models.Patent import FullPatent\n",
    "from api.repositories.patent_repository import update_full_patent\n",
    "\n",
    "# Dict of SDG candidate labels\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}\n",
    "\n",
    "candidate_label_values = list(sdg_labels_dict.values())\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = pipeline(model=\"facebook/bart-large-mnli\", token=ai_huggingface_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdg_code_from_label(label: str, label_dict: dict) -> str:\n",
    "    \"\"\"Reverse lookup SDG code from full label text.\"\"\"\n",
    "    for code, text in label_dict.items():\n",
    "        if label == text:\n",
    "            return code\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "def classify_full_patent_description(patent: FullPatent,\n",
    "                                     classifier=classifier,\n",
    "                                     candidate_labels=candidate_label_values,\n",
    "                                     label_dict=sdg_labels_dict,\n",
    "                                     treshold: float = 0.18) -> FullPatent:\n",
    "    \"\"\"\n",
    "    Classify all description blocks in a FullPatent and enrich them with SDG labels.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent to analyze.\n",
    "        classifier: HuggingFace classifier.\n",
    "        candidate_labels (list): SDG label texts.\n",
    "        label_dict (dict): Map from SDG label text to SDG code.\n",
    "        treshold (float): Minimum score to accept prediction.\n",
    "\n",
    "    Returns:\n",
    "        FullPatent: Enriched object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Filter descriptions with enough length\n",
    "    valid_descriptions = [(desc, desc.description_text) \n",
    "                          for desc in patent.description \n",
    "                          if len(desc.description_text.split()) > 20]\n",
    "\n",
    "    # Step 2: Extract just the text for classification\n",
    "    texts_to_classify = [text for _, text in valid_descriptions]\n",
    "\n",
    "    # Step 3: Run classifier on batch\n",
    "    results = classifier(texts_to_classify, candidate_labels=candidate_labels)\n",
    "\n",
    "    # Step 4: Assign results back to descriptions\n",
    "    for (desc, _), result in zip(valid_descriptions, results):\n",
    "\n",
    "        try:\n",
    "            top_score = result[\"scores\"][0]\n",
    "            if top_score >= treshold:\n",
    "                label_text = result[\"labels\"][0]\n",
    "                desc.sdg = get_sdg_code_from_label(label_text, label_dict)\n",
    "            else:\n",
    "                desc.sdg = \"None\"\n",
    "                top_score = -1\n",
    "\n",
    "            # print(f\"[{desc.description_number}] Label: {desc.sdg} | Score: {top_score:.3f} | Text: {desc.description_text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error on description {desc.description_number}: {e}\")\n",
    "            desc.sdg = \"Error\"\n",
    "\n",
    "    # Step 5: Handle short descriptions (not classified)\n",
    "    for desc in patent.description:\n",
    "        if len(desc.description_text.split()) <= 20:\n",
    "            desc.sdg = \"None\"\n",
    "\n",
    "    patent.is_analyzed = True\n",
    "\n",
    "    # Update the Patent in Database\n",
    "    update_full_patent(patent.model_dump())\n",
    "\n",
    "    return patent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc948a",
   "metadata": {},
   "source": [
    "#### 1.2.2. Run analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cceb8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "\n",
    "def load_already_classified_patents(file_path: str) -> set:\n",
    "    \"\"\"Charge les brevets d√©j√† enregistr√©s dans le fichier JSONL.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return set()\n",
    "\n",
    "    classified = set()\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                classified.add(item[\"patent_number\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading line: {e}\")\n",
    "    return classified\n",
    "\n",
    "\n",
    "def save_classified_descriptions(data: List[Dict], file_path: str):\n",
    "    \"\"\"Ajoute les nouvelles descriptions √† la fin du fichier JSONL.\"\"\"\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def analyze_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "    random.shuffle(to_process)\n",
    "\n",
    "    for patent_number in to_process:\n",
    "        try:\n",
    "            print(f\"\\nProcessing patent {patent_number}...\")\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            enriched_patent = classify_full_patent_description(patent)\n",
    "\n",
    "            output_data = []\n",
    "            for desc in enriched_patent.description:\n",
    "                output_data.append({\n",
    "                    \"patent_number\": patent_number,\n",
    "                    \"description_number\": desc.description_number,\n",
    "                    \"description_text\": desc.description_text,\n",
    "                    \"sdg\": desc.sdg\n",
    "                })\n",
    "\n",
    "            save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a42de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse all patents\n",
    "analyze_patents_and_save_descriptions(all_patents_number, export_file=\"classified_patents_raw.jsonl\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7f525",
   "metadata": {},
   "source": [
    "#### 1.2.3. Remove Duplicates\n",
    "\n",
    "To ensure the quality of the dataset, we remove duplicate entries (doublons) from the classified results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376a14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analyze_and_save_clean_jsonl(file_path, output_path):\n",
    "    seen_pairs = set()\n",
    "    total_lines = 0\n",
    "    duplicate_lines = 0\n",
    "    duplicate_patents = []\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            try:\n",
    "                total_lines += 1\n",
    "                item = json.loads(line.strip())\n",
    "                pair = (item.get(\"patent_number\"), item.get(\"description_text\"))\n",
    "\n",
    "                if pair in seen_pairs:\n",
    "                    duplicate_lines += 1\n",
    "                    duplicate_patents.append(item.get(\"patent_number\"))\n",
    "                else:\n",
    "                    seen_pairs.add(pair)\n",
    "                    outfile.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "    print(f\"Duplicate (patent_number, description_text) pairs: {duplicate_lines}\")\n",
    "    print(f\"Unique (patent_number, description_text) pairs saved: {len(seen_pairs)}\")\n",
    "\n",
    "    return total_lines, duplicate_lines, duplicate_patents\n",
    "\n",
    "\n",
    "input_path = \"classified_patents_raw.jsonl\"\n",
    "output_path = \"classified_patents_raw_clean.jsonl\"\n",
    "analyze_and_save_clean_jsonl(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff7b21",
   "metadata": {},
   "source": [
    "#### 1.2.4. Check if duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e943a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_jsonl_by_patent_and_description(file_path):\n",
    "    seen_pairs = set()\n",
    "    total_lines = 0\n",
    "    duplicate_lines = 0\n",
    "    duplicate_patents = []\n",
    "\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                total_lines += 1\n",
    "                item = json.loads(line.strip())\n",
    "                pair = (item.get(\"patent_number\"), item.get(\"description_text\"))\n",
    "\n",
    "                if pair in seen_pairs:\n",
    "                    duplicate_lines += 1\n",
    "                    duplicate_patents.append(item.get(\"patent_number\"))\n",
    "                else:\n",
    "                    seen_pairs.add(pair)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "    print(f\"Duplicate (patent_number, description_number) pairs: {duplicate_lines}\")\n",
    "    print(f\"Unique (patent_number, description_number) pairs: {len(seen_pairs)}\")\n",
    "\n",
    "    return total_lines, duplicate_lines, duplicate_patents\n",
    "\n",
    "# Exemple d'utilisation\n",
    "analyze_jsonl_by_patent_and_description('classified_patents_raw_clean.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca4ea8",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äì Create a balanced test set\n",
    "\n",
    "To ensure class balance:\n",
    "- Group data by `sdg_pred`\n",
    "- Shuffle each group\n",
    "- Sample 10 items per class\n",
    "\n",
    "The selected items are saved in testset_[version]_[language].jsonl."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1fe20",
   "metadata": {},
   "source": [
    "#### 1.3.1. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e06bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from typing import List\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "DetectorFactory.seed = 0  # R√©sultats reproductibles\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang in {\"fr\", \"en\", \"de\"}:\n",
    "            return lang\n",
    "    except LangDetectException:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def generate_classified_patents_raw(\n",
    "    jsonl_file: str,\n",
    "    version: str = \"v0\",\n",
    "    max_per_sdg: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Optimized: Detect language once per unique patent_number, applied to all its entries.\n",
    "    Also prints statistics per SDG.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Group items by patent_number (to ensure uniqueness and batch language detection)\n",
    "    items_by_patent = defaultdict(list)\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                patent_number = item.get(\"patent_number\")\n",
    "                if patent_number:\n",
    "                    items_by_patent[patent_number].append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur parsing JSON : {e}\")\n",
    "\n",
    "    # 2. Detect language once per patent_number, then group items by language and SDG\n",
    "    grouped_by_lang = {\n",
    "        \"fr\": defaultdict(list),\n",
    "        \"en\": defaultdict(list),\n",
    "        \"de\": defaultdict(list)\n",
    "    }\n",
    "\n",
    "    for patent_number, items in items_by_patent.items():\n",
    "        # Find first non-empty description text to detect language\n",
    "        for item in items:\n",
    "            text = item.get(\"description_text\", \"\").strip()\n",
    "            if text:\n",
    "                lang = detect_language(text)\n",
    "                break\n",
    "        else:\n",
    "            lang = None\n",
    "\n",
    "        # If language detected and supported, group items by SDG under that language\n",
    "        if lang in grouped_by_lang:\n",
    "            for item in items:\n",
    "                sdg = item.get(\"sdg\")\n",
    "                if sdg is not None:\n",
    "                    grouped_by_lang[lang][sdg].append(item)\n",
    "\n",
    "    # 3. For each language, shuffle and select up to max_per_sdg items per SDG, then write to file\n",
    "    for lang, grouped in grouped_by_lang.items():\n",
    "        testset: List[dict] = []\n",
    "        per_class_count = {}\n",
    "        for sdg, items in grouped.items():\n",
    "            random.shuffle(items)\n",
    "            selected = items[:max_per_sdg]\n",
    "            testset.extend(selected)\n",
    "            per_class_count[sdg] = len(selected)\n",
    "\n",
    "        output_file = f\"testset_{version}_{lang}_raw.jsonl\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "            for item in testset:\n",
    "                out.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "        print(f\"\\n{output_file} g√©n√©r√© avec {len(testset)} √©l√©ments.\")\n",
    "        print(\"R√©partition par SDG :\")\n",
    "        for sdg in sorted(per_class_count):\n",
    "            print(f\"  SDG {sdg:>2}: {per_class_count[sdg]} √©l√©ments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f3fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testset_v3_fr_raw.jsonl g√©n√©r√© avec 98 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG1: 1 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 6 √©l√©ments\n",
      "  SDG SDG14: 10 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 3 √©l√©ments\n",
      "  SDG SDG17: 6 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v3_en_raw.jsonl g√©n√©r√© avec 122 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG11: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 10 √©l√©ments\n",
      "  SDG SDG14: 8 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 7 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 10 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG8: 3 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v3_de_raw.jsonl g√©n√©r√© avec 78 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 2 √©l√©ments\n",
      "  SDG SDG14: 9 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 1 √©l√©ments\n",
      "  SDG SDG2: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n"
     ]
    }
   ],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"classified_patents_raw_clean.jsonl\", version=\"v1\", max_per_sdg=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035af862",
   "metadata": {},
   "source": [
    "#### 1.3.2. Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2fdc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def trouver_doublons_jsonl(fichier_jsonl):\n",
    "    \"\"\"\n",
    "    Find duplicates in a JSONL file based on 'patent_number' and 'description_text'.\n",
    "\n",
    "    Args:\n",
    "        jsonl_file (str): Path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: List of duplicate entries (each as a dictionary).\n",
    "    \"\"\"\n",
    "    vus = defaultdict(list)\n",
    "    doublons = []\n",
    "\n",
    "    with open(fichier_jsonl, 'r', encoding='utf-8') as f:\n",
    "        for ligne in f:\n",
    "            try:\n",
    "                item = json.loads(ligne.strip())\n",
    "                cle = (item.get('patent_number'), item.get('description_text'))\n",
    "                vus[cle].append(item)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipped line due to parsing error : {e}\")\n",
    "\n",
    "    for items in vus.values():\n",
    "        if len(items) > 1:\n",
    "            doublons.extend(items)\n",
    "\n",
    "    return doublons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca319778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"testset_v1_en_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trouver_doublons_jsonl(\"testset_v1_fr_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86fa522",
   "metadata": {},
   "outputs": [],
   "source": [
    "trouver_doublons_jsonl(\"testset_v1_de_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850b6c4",
   "metadata": {},
   "source": [
    "## Optional Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a14832",
   "metadata": {},
   "source": [
    "### Retrieve all patent numbers from the database\n",
    "\n",
    "If you want to retrieve the labeled data from the database instead of regenerating it, you can use the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2fe440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa5c68dd8a4a4eb84cf8d2e5b2c626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching patent numbers by batch:   0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from api.services.patent_service import get_all_patents\n",
    "\n",
    "def get_all_patents_number_if_analysed():\n",
    "    \"\"\"\n",
    "    Retrieve all patent numbers from the database in batches of 100.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing all patent numbers.\n",
    "    \"\"\"\n",
    "    all_patents_number = []\n",
    "\n",
    "    # Step 1: Get total number of patents\n",
    "    patents = get_all_patents()\n",
    "    total_patents = patents.total_count\n",
    "\n",
    "    # Step 2: Iterate through all patents in batches of 100 with progress tracking\n",
    "    for i in tqdm(range(0, total_patents, 100), desc=\"Fetching patent numbers by batch\"):\n",
    "        # Step 3: Fetch a batch of patents\n",
    "        patents_batch = get_all_patents(first=i, last=i+100)\n",
    "\n",
    "        # Step 4: Extract patent numbers from the current batch\n",
    "        for patent in patents_batch.patents:\n",
    "            if patent.is_analyzed:\n",
    "                all_patents_number.append(patent.number)\n",
    "\n",
    "    return all_patents_number\n",
    "\n",
    "# Example usage\n",
    "all_patents_number_if_analysed = get_all_patents_number_if_analysed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267f1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def db_get_patents_and_save_descriptions(patent_numbers: List[str], export_file: str = \"classified_patents_raw_test.jsonl\"):\n",
    "    already_classified = load_already_classified_patents(export_file)\n",
    "    to_process = [pn for pn in patent_numbers if pn not in already_classified]\n",
    "\n",
    "    print(f\"Total patents to process: {len(to_process)}\")\n",
    "\n",
    "\n",
    "    for patent_number in tqdm(to_process, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            patent = get_full_patent_by_number(patent_number)\n",
    "            # If analysed patent save it\n",
    "            if patent.is_analyzed:\n",
    "                output_data = []\n",
    "                for desc in patent.description:\n",
    "                    output_data.append({\n",
    "                        \"patent_number\": patent_number,\n",
    "                        \"description_number\": desc.description_number,\n",
    "                        \"description_text\": desc.description_text,\n",
    "                        \"sdg\": desc.sdg\n",
    "                    })\n",
    "\n",
    "                save_classified_descriptions(output_data, export_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patents to process: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fbfcf0fec94600a90d55368e863034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Patent recovered: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing completed and data saved.\n"
     ]
    }
   ],
   "source": [
    "db_get_patents_and_save_descriptions(all_patents_number_if_analysed, export_file=\"classified_patents_raw_db.jsonl\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Remove duplicates\n",
    "input_path = \"classified_patents_raw_db.jsonl\"\n",
    "output_path = \"classified_patents_raw_db_clean.jsonl\"\n",
    "analyze_and_save_clean_jsonl(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_jsonl_by_patent_and_description('classified_patents_raw_clean.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de9ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testset_v2_fr_raw.json g√©n√©r√© avec 98 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG1: 1 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 6 √©l√©ments\n",
      "  SDG SDG14: 10 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 3 √©l√©ments\n",
      "  SDG SDG17: 6 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v2_en_raw.json g√©n√©r√© avec 122 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG11: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 10 √©l√©ments\n",
      "  SDG SDG14: 8 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 7 √©l√©ments\n",
      "  SDG SDG3: 10 √©l√©ments\n",
      "  SDG SDG4: 10 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG8: 3 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n",
      "\n",
      "testset_v2_de_raw.json g√©n√©r√© avec 78 √©l√©ments.\n",
      "R√©partition par SDG :\n",
      "  SDG None: 10 √©l√©ments\n",
      "  SDG SDG10: 10 √©l√©ments\n",
      "  SDG SDG12: 10 √©l√©ments\n",
      "  SDG SDG13: 2 √©l√©ments\n",
      "  SDG SDG14: 9 √©l√©ments\n",
      "  SDG SDG15: 10 √©l√©ments\n",
      "  SDG SDG16: 4 √©l√©ments\n",
      "  SDG SDG17: 1 √©l√©ments\n",
      "  SDG SDG2: 2 √©l√©ments\n",
      "  SDG SDG6: 10 √©l√©ments\n",
      "  SDG SDG9: 10 √©l√©ments\n"
     ]
    }
   ],
   "source": [
    "generate_classified_patents_raw(jsonl_file=\"classified_patents_raw_db_clean.jsonl\", version=\"db_v1\", max_per_sdg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e67a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"testset_db_v1_en_raw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0798b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"testset_db_v1_fr_raw.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177351d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trouver_doublons_jsonl(\"testset_db_v1_de_raw.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adca1f",
   "metadata": {},
   "source": [
    "### Generate SDG justification summaries for a FullPatent.\n",
    "\n",
    "This function allows you to generate summary justifications for the patents that have already been classified. These summaries can then be used to update the database, ensuring that the front-end displays the most up-to-date and relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0cbe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.models.Patent import FullPatent\n",
    "from api.models.SDGSummary import SDGSummary\n",
    "\n",
    "def generate_summary(patent: FullPatent,\n",
    "                     ai_client,\n",
    "                     ai_model: str,\n",
    "                     sdg_labels_dict: dict) -> list[SDGSummary]:\n",
    "    \"\"\"\n",
    "    Generate SDG justification summaries for a FullPatent.\n",
    "\n",
    "    This function groups description blocks by their assigned SDG labels \n",
    "    (excluding \"None\" or \"Error\"), then uses an AI model to generate a \n",
    "    summary explaining how the content supports the respective SDG.\n",
    "\n",
    "    Args:\n",
    "        patent (FullPatent): The patent object containing the description blocks.\n",
    "        ai_client: AI client used to generate summaries.\n",
    "        ai_model (str): The identifier of the AI model to be used.\n",
    "        sdg_labels_dict (dict): Mapping from SDG codes to their textual descriptions.\n",
    "\n",
    "    Returns:\n",
    "        list[SDGSummary]: A list of SDGSummary objects created for the patent.\n",
    "    \"\"\"\n",
    "\n",
    "    summaries = []\n",
    "\n",
    "    # Group descriptions by SDG label, excluding \"None\" and \"Error\"\n",
    "    sdg_to_descriptions = {}\n",
    "    for desc in patent.description:\n",
    "        if desc.sdg not in [\"None\", \"Error\"]:\n",
    "            sdg_to_descriptions.setdefault(desc.sdg, []).append(desc)\n",
    "\n",
    "    for sdg_code, descriptions in tqdm(sdg_to_descriptions.items(), desc=f\"Generating summaries for patent {patent.number}\"):\n",
    "        try:\n",
    "            sdg_description = sdg_labels_dict[sdg_code]\n",
    "            combined_text = \"\\n\".join(desc.description_text for desc in descriptions)\n",
    "\n",
    "            system_prompt = f\"\"\"\n",
    "            You are an AI specialized in sustainable development and patents. Read the following patent excerpt and explain how it contributes to this Sustainable Development Goal (SDG): {sdg_code} - {sdg_description}.\n",
    "\n",
    "            Focus on:\n",
    "            - The main innovation or idea in the patent.\n",
    "            - How it supports the targets of the SDG.\n",
    "            - Any positive impact (social, environmental, or economic) it may have.\n",
    "\n",
    "            Patent text:\n",
    "            {combined_text}\n",
    "\n",
    "            Write a short, clear summary showing the link between the patent and the SDG.\n",
    "            \"\"\"\n",
    "\n",
    "            user_prompt = f\"\"\"\n",
    "            Summarize how this patent helps achieve the SDG: {sdg_code} - {sdg_description}.\"\"\"\n",
    "\n",
    "            response = ai_client.chat(\n",
    "                model=ai_model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}],\n",
    "                options = {\"num_predict\":512}\n",
    "            )\n",
    "\n",
    "            summary_text = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "            summary = SDGSummary(\n",
    "                patent_number=str(patent.number),\n",
    "                sdg=str(sdg_code),\n",
    "                sdg_description=summary_text\n",
    "            )\n",
    "\n",
    "            summaries.append(summary)\n",
    "\n",
    "            # print(f\"[{patent.number}] SDG: {sdg_code} | Summary:\\n{summary_text}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating summary for SDG {sdg_code} in patent {patent.number}: {e}\")\n",
    "\n",
    "    return summaries\n",
    "\n",
    "\n",
    "sdg_labels_dict = {\n",
    "    \"SDG1\": \"End poverty in all its forms everywhere\", \n",
    "    \"SDG2\": \"End hunger, achieve food security and improved nutrition and promote sustainable agriculture\", \n",
    "    \"SDG3\": \"Ensure healthy lives and promote well-being for all at all ages\", \n",
    "    \"SDG4\": \"Ensure inclusive and equitable quality education and promote lifelong learning opportunities for all\", \n",
    "    \"SDG5\": \"Achieve gender equality and empower all women and girls\", \n",
    "    \"SDG6\": \"Ensure availability and sustainable management of water and sanitation for all\", \n",
    "    \"SDG7\": \"Ensure access to affordable, reliable, sustainable and modern energy for all\", \n",
    "    \"SDG8\": \"Promote sustained, inclusive and sustainable economic growth, full and productive employment and decent work for all\", \n",
    "    \"SDG9\": \"Build resilient infrastructure, promote inclusive and sustainable industrialization and foster innovation\", \n",
    "    \"SDG10\": \"Reduce inequality within and among countries\", \n",
    "    \"SDG11\": \"Make cities and human settlements inclusive, safe, resilient and sustainable\", \n",
    "    \"SDG12\": \"Ensure sustainable consumption and production patterns\", \n",
    "    \"SDG13\": \"Take urgent action to combat climate change and its impacts\", \n",
    "    \"SDG14\": \"Conserve and sustainably use the oceans, seas and marine resources for sustainable development\", \n",
    "    \"SDG15\": \"Protect, restore and promote sustainable use of terrestrial ecosystems, sustainably manage forests, combat desertification, and halt and reverse land degradation and halt biodiversity loss\", \n",
    "    \"SDG16\": \"Promote peaceful and inclusive societies for sustainable development, provide access to justice for all and build effective, accountable and inclusive institutions at all levels\", \n",
    "    \"SDG17\": \"Strengthen the means of implementation and revitalize the Global Partnership for Sustainable Development\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46402363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.repositories.sdg_summary_repository import get_sdg_summary_by_patent_number\n",
    "from api.services.patent_service import get_full_patent_by_number\n",
    "from api.repositories.sdg_summary_repository import create_sdg_summary\n",
    "from api.config.ai_config import ai_model, ai_client\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_summaries_for_patent_in_db_analysed(patent_numbers: List[str]):\n",
    "\n",
    "    for patent_number in tqdm(patent_numbers, desc=\"Patent recovered\"):\n",
    "        try:\n",
    "            # We check if a summary already exists\n",
    "            summaries = get_sdg_summary_by_patent_number(patent_number)\n",
    "\n",
    "            if not summaries:\n",
    "                patent = get_full_patent_by_number(patent_number)\n",
    "                summaries = generate_summary(patent, ai_client, ai_model, sdg_labels_dict)\n",
    "                \n",
    "                # Save in bdd\n",
    "                for summary in summaries:\n",
    "                    create_sdg_summary(summary.model_dump())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {patent_number}: {e}\")\n",
    "\n",
    "    print(\"\\nProcessing completed and summaries generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_summaries_for_patent_in_db_analysed(all_patents_number_if_analysed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
